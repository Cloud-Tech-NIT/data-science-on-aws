{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc882d63-47aa-4a8d-a617-426877630e37",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "  Using cached xgboost-1.6.2-py3-none-manylinux2014_x86_64.whl (255.9 MB)\n",
      "Collecting xgboost_ray\n",
      "  Using cached xgboost_ray-0.1.15-py3-none-any.whl (138 kB)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.7/site-packages (from xgboost) (1.4.1)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from xgboost) (1.21.6)\n",
      "Collecting wrapt>=1.12.1\n",
      "  Using cached wrapt-1.15.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (75 kB)\n",
      "Collecting ray>=1.10\n",
      "  Using cached ray-2.3.0-cp37-cp37m-manylinux2014_x86_64.whl (58.8 MB)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from xgboost_ray) (20.1)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.7/site-packages (from xgboost_ray) (1.3.5)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from ray>=1.10->xgboost_ray) (3.0.12)\n",
      "Collecting virtualenv>=20.0.24\n",
      "  Downloading virtualenv-20.21.0-py3-none-any.whl (8.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.7/8.7 MB\u001b[0m \u001b[31m40.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting grpcio>=1.32.0\n",
      "  Using cached grpcio-1.51.3-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.8 MB)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from ray>=1.10->xgboost_ray) (2.28.2)\n",
      "Requirement already satisfied: jsonschema in /opt/conda/lib/python3.7/site-packages (from ray>=1.10->xgboost_ray) (3.2.0)\n",
      "Requirement already satisfied: frozenlist in /opt/conda/lib/python3.7/site-packages (from ray>=1.10->xgboost_ray) (1.3.3)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from ray>=1.10->xgboost_ray) (4.4.0)\n",
      "Collecting msgpack<2.0.0,>=1.0.0\n",
      "  Using cached msgpack-1.0.5-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (299 kB)\n",
      "Requirement already satisfied: protobuf!=3.19.5,>=3.15.3 in /opt/conda/lib/python3.7/site-packages (from ray>=1.10->xgboost_ray) (3.20.3)\n",
      "Requirement already satisfied: click>=7.0 in /opt/conda/lib/python3.7/site-packages (from ray>=1.10->xgboost_ray) (7.0)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.7/site-packages (from ray>=1.10->xgboost_ray) (6.0)\n",
      "Requirement already satisfied: attrs in /opt/conda/lib/python3.7/site-packages (from ray>=1.10->xgboost_ray) (22.2.0)\n",
      "Requirement already satisfied: aiosignal in /opt/conda/lib/python3.7/site-packages (from ray>=1.10->xgboost_ray) (1.3.1)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging->xgboost_ray) (2.4.6)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from packaging->xgboost_ray) (1.14.0)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas->xgboost_ray) (2019.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.7/site-packages (from pandas->xgboost_ray) (2.8.2)\n",
      "Collecting distlib<1,>=0.3.6\n",
      "  Using cached distlib-0.3.6-py2.py3-none-any.whl (468 kB)\n",
      "Collecting filelock\n",
      "  Using cached filelock-3.9.0-py3-none-any.whl (9.7 kB)\n",
      "Requirement already satisfied: platformdirs<4,>=2.4 in /opt/conda/lib/python3.7/site-packages (from virtualenv>=20.0.24->ray>=1.10->xgboost_ray) (3.0.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.8.3 in /opt/conda/lib/python3.7/site-packages (from virtualenv>=20.0.24->ray>=1.10->xgboost_ray) (6.0.0)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in /opt/conda/lib/python3.7/site-packages (from jsonschema->ray>=1.10->xgboost_ray) (0.15.7)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from jsonschema->ray>=1.10->xgboost_ray) (59.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->ray>=1.10->xgboost_ray) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->ray>=1.10->xgboost_ray) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.7/site-packages (from requests->ray>=1.10->xgboost_ray) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->ray>=1.10->xgboost_ray) (1.26.14)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata>=4.8.3->virtualenv>=20.0.24->ray>=1.10->xgboost_ray) (3.13.0)\n",
      "Installing collected packages: msgpack, distlib, wrapt, grpcio, filelock, xgboost, virtualenv, ray, xgboost_ray\n",
      "  Attempting uninstall: msgpack\n",
      "    Found existing installation: msgpack 0.6.1\n",
      "    Uninstalling msgpack-0.6.1:\n",
      "      Successfully uninstalled msgpack-0.6.1\n",
      "  Attempting uninstall: wrapt\n",
      "    Found existing installation: wrapt 1.11.2\n",
      "    Uninstalling wrapt-1.11.2:\n",
      "      Successfully uninstalled wrapt-1.11.2\n",
      "  Attempting uninstall: filelock\n",
      "    Found existing installation: filelock 3.0.12\n",
      "    Uninstalling filelock-3.0.12:\n",
      "      Successfully uninstalled filelock-3.0.12\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "aiobotocore 2.4.2 requires botocore<1.27.60,>=1.27.59, but you have botocore 1.29.69 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed distlib-0.3.6 filelock-3.9.0 grpcio-1.51.3 msgpack-1.0.5 ray-2.3.0 virtualenv-20.21.0 wrapt-1.15.0 xgboost-1.6.2 xgboost_ray-0.1.15\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install xgboost xgboost_ray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de856b0a-8b1a-4a53-8e04-30bf90ca3009",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "import ray\n",
    "ray.shutdown()\n",
    "\n",
    "from ray import tune\n",
    "from ray.air.checkpoint import Checkpoint\n",
    "from ray.train.constants import TRAIN_DATASET_KEY\n",
    "\n",
    "from ray.train.xgboost import XGBoostCheckpoint, XGBoostTrainer\n",
    "from ray.air.config import ScalingConfig\n",
    "from ray.data.preprocessor import Preprocessor\n",
    "\n",
    "# from sklearn.datasets import load_breast_cancer\n",
    "# from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "064be4a4-7e70-488c-a41c-70cd52955bc6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-14 04:30:33,619\tWARNING services.py:1791 -- WARNING: The object store is using /tmp instead of /dev/shm because /dev/shm has only 4044357632 bytes available. This will harm performance! You may be able to free up space by deleting files in /dev/shm. If you are inside a Docker container, you can increase /dev/shm size by passing '--shm-size=10.00gb' to 'docker run' (or add it to the run_options list in a Ray cluster config). Make sure to set this to more than 30% of available RAM.\n",
      "2023-03-14 04:30:33,744\tINFO worker.py:1553 -- Started a local Ray instance.\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing\n",
    "import ray\n",
    "\n",
    "num_cpus = multiprocessing.cpu_count()\n",
    "\n",
    "ray.shutdown()\n",
    "address_info = ray.init(num_cpus=num_cpus - 1) #,log_dir='/tmp/ray_results/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b592628-28db-40b8-82d6-b6556b0341f9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_get_read_tasks pid=1139)\u001b[0m /opt/conda/lib/python3.7/site-packages/ray/data/datasource/parquet_datasource.py:233: FutureWarning: 'ParquetDataset.pieces' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Use the '.fragments' attribute instead\n",
      "\u001b[2m\u001b[36m(_get_read_tasks pid=1139)\u001b[0m   pq_ds.pieces, **prefetch_remote_args\n",
      "\u001b[2m\u001b[36m(_get_read_tasks pid=1139)\u001b[0m /opt/conda/lib/python3.7/site-packages/ray/data/datasource/parquet_datasource.py:311: FutureWarning: 'ParquetDataset.pieces' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Use the '.fragments' attribute instead\n",
      "\u001b[2m\u001b[36m(_get_read_tasks pid=1139)\u001b[0m   num_files = len(self._pq_ds.pieces)\n",
      "\u001b[2m\u001b[36m(_get_read_tasks pid=1139)\u001b[0m /opt/conda/lib/python3.7/site-packages/ray/data/datasource/parquet_datasource.py:325: FutureWarning: 'ParquetDataset.pieces' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Use the '.fragments' attribute instead\n",
      "\u001b[2m\u001b[36m(_get_read_tasks pid=1139)\u001b[0m   for idx in np.linspace(0, num_files - 1, num_samples).astype(int).tolist()\n",
      "Parquet Files Sample:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "2023-03-14 04:30:36,367\tINFO tensorboardx.py:170 -- pip install \"ray[tune]\" to see TensorBoard files.\n",
      "2023-03-14 04:30:36,368\tWARNING callback.py:109 -- The TensorboardX logger cannot be instantiated because either TensorboardX or one of it's dependencies is not installed. Please make sure you have the latest version of TensorboardX installed: `pip install -U tensorboardx`\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2023-03-14 05:13:06</td></tr>\n",
       "<tr><td>Running for: </td><td>00:42:30.04        </td></tr>\n",
       "<tr><td>Memory:      </td><td>3.7/31.0 GiB       </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using FIFO scheduling algorithm.<br>Resources requested: 7.0/7 CPUs, 0/0 GPUs, 0.0/18.18 GiB heap, 0.0/9.09 GiB objects\n",
       "    </div>\n",
       "    \n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name                </th><th>status  </th><th>loc               </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>XGBoostTrainer_f764c_00000</td><td>RUNNING </td><td>169.255.255.2:1586</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parquet Files Sample: 100%|██████████| 2/2 [00:01<00:00,  1.87it/s]\n",
      "\u001b[2m\u001b[36m(_get_read_tasks pid=1139)\u001b[0m /opt/conda/lib/python3.7/site-packages/ray/data/datasource/parquet_datasource.py:263: FutureWarning: 'ParquetDataset.pieces' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Use the '.fragments' attribute instead\n",
      "\u001b[2m\u001b[36m(_get_read_tasks pid=1139)\u001b[0m   np.array_split(self._pq_ds.pieces, parallelism),\n",
      "\u001b[2m\u001b[36m(XGBoostTrainer pid=1586)\u001b[0m 2023-03-14 04:30:39,023\tWARNING plan.py:524 -- Warning: The Ray cluster currently does not have any available CPUs. The Dataset job will hang unless more CPUs are freed up. A common reason is that cluster resources are used by Actors or Tune trials; see the following link for more details: https://docs.ray.io/en/master/data/dataset-internals.html#datasets-and-tune\n",
      "\u001b[2m\u001b[36m(XGBoostTrainer pid=1586)\u001b[0m 2023-03-14 04:30:39,032\tINFO bulk_executor.py:39 -- Executing DAG InputDataBuffer[Input] -> TaskPoolMapOperator[read] -> AllToAllOperator[repartition]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[1m\u001b[36m(autoscaler +16s)\u001b[0m Tip: use `ray status` to view detailed cluster status. To disable these messages, set RAY_SCHEDULER_EVENTS=0.\n",
      "\u001b[2m\u001b[1m\u001b[33m(autoscaler +16s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(autoscaler +52s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(autoscaler +1m27s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(autoscaler +2m2s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(autoscaler +2m37s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(autoscaler +3m12s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(autoscaler +3m47s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(autoscaler +4m22s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(autoscaler +4m57s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(autoscaler +5m32s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(autoscaler +6m7s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(autoscaler +6m42s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(autoscaler +7m17s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(autoscaler +7m52s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(autoscaler +8m27s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(autoscaler +9m2s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(autoscaler +9m37s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(autoscaler +10m12s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(autoscaler +10m47s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(autoscaler +11m22s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(autoscaler +11m58s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(autoscaler +12m33s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(autoscaler +13m8s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(autoscaler +13m43s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(autoscaler +14m18s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(autoscaler +14m53s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(autoscaler +15m28s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(autoscaler +16m3s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(autoscaler +16m38s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(autoscaler +17m13s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(autoscaler +17m48s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(autoscaler +18m23s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(autoscaler +18m58s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(autoscaler +19m33s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(autoscaler +20m8s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(autoscaler +20m43s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(autoscaler +21m18s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(autoscaler +21m53s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(autoscaler +22m28s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(autoscaler +23m4s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(autoscaler +23m39s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(autoscaler +24m14s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(autoscaler +24m49s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(autoscaler +25m24s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(autoscaler +25m59s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(autoscaler +26m34s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(autoscaler +27m9s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(autoscaler +27m44s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(autoscaler +28m19s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(autoscaler +28m54s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(autoscaler +29m29s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(autoscaler +30m4s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(autoscaler +30m39s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(autoscaler +31m14s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(autoscaler +31m49s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(autoscaler +32m24s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(autoscaler +32m59s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(autoscaler +33m34s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(autoscaler +34m9s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(autoscaler +34m45s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(autoscaler +35m20s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(autoscaler +35m55s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(autoscaler +36m30s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(autoscaler +37m5s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(autoscaler +37m40s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(autoscaler +38m15s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(autoscaler +38m50s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(autoscaler +39m25s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(autoscaler +40m0s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(autoscaler +40m35s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(autoscaler +41m10s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(autoscaler +41m45s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(autoscaler +42m20s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-14 05:13:05,369\tWARNING tune.py:147 -- Stop signal received (e.g. via SIGINT/Ctrl+C), ending Ray Tune run. This will try to checkpoint the experiment state one last time. Press CTRL+C (or send SIGINT/SIGKILL/SIGTERM) to skip. \n",
      "2023-03-14 05:13:06,417\tERROR tune.py:794 -- Trials did not complete: [XGBoostTrainer_f764c_00000]\n",
      "2023-03-14 05:13:06,418\tINFO tune.py:799 -- Total run time: 2550.05 seconds (2550.01 seconds for the tuning loop).\n",
      "2023-03-14 05:13:06,419\tWARNING tune.py:805 -- Experiment has been interrupted, but the most recent state was saved. You can continue running this experiment by passing `resume=True` to `tune.run()`\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'train-rmse'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-387952d84fc2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;31m# Report results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"train rmse = {result.metrics['train-rmse']}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0;31m#print(f\"valid acc = {1 - result.metrics['valid-error']:.4f}\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"iteration = {result.metrics['training_iteration']}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'train-rmse'"
     ]
    }
   ],
   "source": [
    "########\n",
    "# DATA #\n",
    "########\n",
    "# Read Parquet file to Ray Dataset\n",
    "dataset = ray.data.read_parquet(\n",
    "    './data/nyc-taxi/'\n",
    "#    \"s3://anyscale-training-data/intro-to-ray-air/nyc_taxi_2021.parquet\"\n",
    "#    \"s3://dsoaws/intro-to-ray-air/nyc_taxi_2021.parquet\"\n",
    "#    's3://dsoaws/nyc-taxi-orig-cleaned-dropped-parquet-all-years-multiple-files-100GB/'\n",
    ")\n",
    "\n",
    "# Split data into training and validation subsets\n",
    "#train_dataset, valid_dataset = dataset.train_test_split(test_size=0.3)\n",
    "\n",
    "# Split datasets into blocks for parallel preprocessing\n",
    "# `num_blocks` should be lower than number of cores in the cluster\n",
    "train_dataset = dataset.repartition(num_blocks=96)\n",
    "#valid_dataset = valid_dataset.repartition(num_blocks=5)\n",
    "\n",
    "# Define a preprocessor to normalize the columns by their range\n",
    "#preprocessor = MinMaxScaler(columns=[\"trip_distance\", \"trip_duration\"])\n",
    "\n",
    "############\n",
    "# TRAINING #\n",
    "############\n",
    "\n",
    "# Create XGBoost trainer.\n",
    "# During training, it will use `num_blocks` workers.\n",
    "trainer = XGBoostTrainer(\n",
    "    label_column=\"total_amount\",\n",
    "    num_boost_round=50,\n",
    "    scaling_config=ScalingConfig(\n",
    "        num_workers=num_cpus - 1,\n",
    "        use_gpu=False,  # True for the GPU training, 1 GPU per worker\n",
    "    ),\n",
    "    params={\n",
    "        \"eta\": \"0.2\",\n",
    "        \"gamma\": \"4\",\n",
    "        \"max_depth\": \"5\",\n",
    "        \"min_child_weight\": \"6\",\n",
    "#        \"num_round\": \"50\",\n",
    "        \"objective\": \"reg:squarederror\",\n",
    "        \"subsample\": \"0.7\",\n",
    "        \"verbosity\": \"2\",\n",
    "    },\n",
    "    datasets={\n",
    "        \"train\": train_dataset,\n",
    "    },\n",
    "#    preprocessor=preprocessor,\n",
    ")\n",
    "\n",
    "# Invoke training - this is computationally intensive operation\n",
    "# The resulting object grants access to metrics, checkpoints, and errors\n",
    "result = trainer.fit()\n",
    "\n",
    "# Report results\n",
    "print(f\"train rmse = {result.metrics['train-rmse']}\")\n",
    "#print(f\"valid acc = {1 - result.metrics['valid-error']:.4f}\")\n",
    "print(f\"iteration = {result.metrics['training_iteration']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95c290a3-e443-4214-8ba2-2cfca79818c4",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Resume from checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254d27fc-8184-4dd4-a6f8-9484a64002ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# trainer = XGBoostTrainer(\n",
    "#     scaling_config=scale_config,\n",
    "#     label_column=\"target\",\n",
    "#     params=params,\n",
    "#     num_boost_round=5,\n",
    "#     datasets={TRAIN_DATASET_KEY: train_dataset, \"valid\": valid_dataset},\n",
    "# )\n",
    "# result = trainer.fit()\n",
    "# checkpoint = XGBoostCheckpoint.from_checkpoint(result.checkpoint)\n",
    "# xgb_model = checkpoint.get_model()\n",
    "# assert get_num_trees(xgb_model) == 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee0b5d1d-9897-44f0-93f9-30c69b6303a8",
   "metadata": {},
   "source": [
    "# Tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e3d3da-cbca-4f82-b499-33836e145e36",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainer = XGBoostTrainer(\n",
    "    scaling_config=scale_config,\n",
    "    label_column=\"target\",\n",
    "    params={**params, **{\"max_depth\": 1}},\n",
    "    datasets={TRAIN_DATASET_KEY: train_dataset, \"valid\": valid_dataset},\n",
    ")\n",
    "\n",
    "tune.run(\n",
    "    trainer.as_trainable(),\n",
    "    config={\"params\": {\"max_depth\": tune.randint(2, 4)}},\n",
    "    num_samples=2,\n",
    ")\n",
    "\n",
    "# # Make sure original Trainer is not affected.\n",
    "# assert trainer.params[\"max_depth\"] == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d6ec367-3250-4aad-ab81-44054268af14",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Move checkpoint to a different directory.\n",
    "# checkpoint_dict = result.checkpoint.to_dict()\n",
    "# checkpoint = Checkpoint.from_dict(checkpoint_dict)\n",
    "# checkpoint_path = checkpoint.to_directory(tmpdir)\n",
    "# resume_from = Checkpoint.from_directory(checkpoint_path)\n",
    "\n",
    "# trainer = XGBoostTrainer(\n",
    "#     scaling_config=scale_config,\n",
    "#     label_column=\"target\",\n",
    "#     params=params,\n",
    "#     num_boost_round=5,\n",
    "#     datasets={TRAIN_DATASET_KEY: train_dataset, \"valid\": valid_dataset},\n",
    "#     resume_from_checkpoint=resume_from,\n",
    "# )\n",
    "# result = trainer.fit()\n",
    "# checkpoint = XGBoostCheckpoint.from_checkpoint(result.checkpoint)\n",
    "# model = checkpoint.get_model()\n",
    "# assert get_num_trees(model) == 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127534f9-efe8-4b63-8f4d-76e0bec8265a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# @pytest.mark.parametrize(\n",
    "#     \"freq_end_expected\",\n",
    "#     [\n",
    "#         (4, True, 7),  # 4, 8, 12, 16, 20, 24, 25\n",
    "#         (4, False, 6),  # 4, 8, 12, 16, 20, 24\n",
    "#         (5, True, 5),  # 5, 10, 15, 20, 25\n",
    "#         (0, True, 1),\n",
    "#         (0, False, 0),\n",
    "#     ],\n",
    "# )\n",
    "# def test_checkpoint_freq(ray_start_4_cpus, freq_end_expected):\n",
    "#     freq, end, expected = freq_end_expected\n",
    "\n",
    "#     train_dataset = ray.data.from_pandas(train_df)\n",
    "#     valid_dataset = ray.data.from_pandas(test_df)\n",
    "#     trainer = XGBoostTrainer(\n",
    "#         run_config=ray.air.RunConfig(\n",
    "#             checkpoint_config=ray.air.CheckpointConfig(\n",
    "#                 checkpoint_frequency=freq, checkpoint_at_end=end\n",
    "#             )\n",
    "#         ),\n",
    "#         scaling_config=scale_config,\n",
    "#         label_column=\"target\",\n",
    "#         params=params,\n",
    "#         num_boost_round=25,\n",
    "#         datasets={TRAIN_DATASET_KEY: train_dataset, \"valid\": valid_dataset},\n",
    "#     )\n",
    "#     result = trainer.fit()\n",
    "\n",
    "#     # Assert number of checkpoints\n",
    "#     assert len(result.best_checkpoints) == expected, str(\n",
    "#         [\n",
    "#             (metrics[\"training_iteration\"], _cp._local_path)\n",
    "#             for _cp, metrics in result.best_checkpoints\n",
    "#         ]\n",
    "#     )\n",
    "\n",
    "#     # Assert checkpoint numbers are increasing\n",
    "#     cp_paths = [cp._local_path for cp, _ in result.best_checkpoints]\n",
    "#     assert cp_paths == sorted(cp_paths), str(cp_paths)\n",
    "\n",
    "\n",
    "# def test_preprocessor_in_checkpoint(ray_start_4_cpus, tmpdir):\n",
    "#     train_dataset = ray.data.from_pandas(train_df)\n",
    "#     valid_dataset = ray.data.from_pandas(test_df)\n",
    "\n",
    "#     class DummyPreprocessor(Preprocessor):\n",
    "#         def __init__(self):\n",
    "#             super().__init__()\n",
    "#             self.is_same = True\n",
    "\n",
    "#         def fit(self, dataset):\n",
    "#             self.fitted_ = True\n",
    "\n",
    "#         def _transform_pandas(self, df: \"pd.DataFrame\") -> \"pd.DataFrame\":\n",
    "#             return df\n",
    "\n",
    "#     trainer = XGBoostTrainer(\n",
    "#         scaling_config=scale_config,\n",
    "#         label_column=\"target\",\n",
    "#         params=params,\n",
    "#         datasets={TRAIN_DATASET_KEY: train_dataset, \"valid\": valid_dataset},\n",
    "#         preprocessor=DummyPreprocessor(),\n",
    "#     )\n",
    "#     result = trainer.fit()\n",
    "\n",
    "#     # Move checkpoint to a different directory.\n",
    "#     checkpoint_dict = result.checkpoint.to_dict()\n",
    "#     checkpoint = Checkpoint.from_dict(checkpoint_dict)\n",
    "#     checkpoint_path = checkpoint.to_directory(tmpdir)\n",
    "#     resume_from = Checkpoint.from_directory(checkpoint_path)\n",
    "\n",
    "#     resume_from = XGBoostCheckpoint.from_checkpoint(resume_from)\n",
    "\n",
    "#     model, preprocessor = resume_from.get_model(), resume_from.get_preprocessor()\n",
    "#     assert get_num_trees(model) == 10\n",
    "#     assert preprocessor.is_same\n",
    "#     assert preprocessor.fitted_\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf7fb67-0503-47d9-91c2-eb36f2b1b535",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# train_dataset = ray.data.from_pandas(train_df)\n",
    "# valid_dataset = ray.data.from_pandas(test_df)\n",
    "# #with pytest.raises(KeyError, match=TRAIN_DATASET_KEY):\n",
    "# XGBoostTrainer(\n",
    "#     scaling_config=ScalingConfig(num_workers=2),\n",
    "#     label_column=\"target\",\n",
    "#     params=params,\n",
    "#     datasets={\"valid\": valid_dataset},\n",
    "# )\n",
    "# with pytest.raises(KeyError, match=\"dmatrix_params\"):\n",
    "#     XGBoostTrainer(\n",
    "#         scaling_config=ScalingConfig(num_workers=2),\n",
    "#         label_column=\"target\",\n",
    "#         params=params,\n",
    "#         dmatrix_params={\"data\": {}},\n",
    "#         datasets={TRAIN_DATASET_KEY: train_dataset, \"valid\": valid_dataset},\n",
    "#     )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a37ecc-df14-4985-9eac-fd1849b5005b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def test_distributed_data_loading(ray_start_4_cpus):\n",
    "#     \"\"\"Checks that XGBoostTrainer does distributed data loading for Ray Datasets.\"\"\"\n",
    "\n",
    "#     class DummyXGBoostTrainer(XGBoostTrainer):\n",
    "#         def _train(self, params, dtrain, **kwargs):\n",
    "#             assert dtrain.distributed\n",
    "#             return super()._train(params=params, dtrain=dtrain, **kwargs)\n",
    "\n",
    "#     train_dataset = ray.data.from_pandas(train_df)\n",
    "\n",
    "#     trainer = DummyXGBoostTrainer(\n",
    "#         scaling_config=ScalingConfig(num_workers=2),\n",
    "#         label_column=\"target\",\n",
    "#         params=params,\n",
    "#         datasets={TRAIN_DATASET_KEY: train_dataset},\n",
    "#     )\n",
    "\n",
    "#     assert trainer.dmatrix_params[TRAIN_DATASET_KEY][\"distributed\"]\n",
    "#     trainer.fit()\n"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   }
  ],
  "instance_type": "ml.m5.2xlarge",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
