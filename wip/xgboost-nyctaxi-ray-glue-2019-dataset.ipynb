{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd758f9b-126f-45ff-a124-94f83d41126f",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Proposed Solution 1:  SageMaker + Glue Interactive Sessions with Ray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8f759e14-cbe3-416f-9e06-833e4dcadef9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping session: a665821a-e28a-4c63-822e-d7b25f18c97d\n",
      "Stopped session.\n"
     ]
    }
   ],
   "source": [
    "%stop_session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e1451e2b-15a1-4f41-81f2-a3ad44528419",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "# Available Magic Commands\n",
       "\n",
       "## Sessions Magic\n",
       "\n",
       "----\n",
       "    %help                             Return a list of descriptions and input types for all magic commands. \n",
       "    %profile            String        Specify a profile in your aws configuration to use as the credentials provider.\n",
       "    %region             String        Specify the AWS region in which to initialize a session. \n",
       "                                      Default from ~/.aws/config on Linux or macOS, \n",
       "                                      or C:\\Users\\ USERNAME \\.aws\\config\" on Windows.\n",
       "    %idle_timeout       Int           The number of minutes of inactivity after which a session will timeout. \n",
       "                                      Default: 2880 minutes (48 hours).\n",
       "    %session_id_prefix  String        Define a String that will precede all session IDs in the format \n",
       "                                      [session_id_prefix]-[session_id]. If a session ID is not provided,\n",
       "                                      a random UUID will be generated.\n",
       "    %status                           Returns the status of the current Glue session including its duration, \n",
       "                                      configuration and executing user / role.\n",
       "    %session_id                       Returns the session ID for the running session. \n",
       "    %list_sessions                    Lists all currently running sessions by ID.\n",
       "    %stop_session                     Stops the current session.\n",
       "    %glue_version       String        The version of Glue to be used by this session. \n",
       "                                      Currently, the only valid options are 2.0 and 3.0. \n",
       "                                      Default: 2.0.\n",
       "----\n",
       "\n",
       "## Selecting Job Types\n",
       "\n",
       "----\n",
       "    %streaming          String        Sets the session type to Glue Streaming.\n",
       "    %etl                String        Sets the session type to Glue ETL.\n",
       "    %glue_ray           String        Sets the session type to Glue Ray.\n",
       "----\n",
       "\n",
       "## Glue Config Magic \n",
       "*(common across all job types)*\n",
       "\n",
       "----\n",
       "\n",
       "    %%configure         Dictionary    A json-formatted dictionary consisting of all configuration parameters for \n",
       "                                      a session. Each parameter can be specified here or through individual magics.\n",
       "    %iam_role           String        Specify an IAM role ARN to execute your session with.\n",
       "                                      Default from ~/.aws/config on Linux or macOS, \n",
       "                                      or C:\\Users\\%USERNAME%\\.aws\\config` on Windows.\n",
       "    %number_of_workers  int           The number of workers of a defined worker_type that are allocated \n",
       "                                      when a session runs.\n",
       "                                      Default: 5.\n",
       "    %additional_python_modules  List  Comma separated list of additional Python modules to include in your cluster \n",
       "                                      (can be from Pypi or S3).\n",
       "----\n",
       "\n",
       "                                      \n",
       "## Magic for Spark Jobs (ETL & Streaming)\n",
       "\n",
       "----\n",
       "    %worker_type        String        Set the type of instances the session will use as workers. \n",
       "                                      ETL and Streaming support G.1X and G.2X. \n",
       "                                      Default: G.1X.\n",
       "    %connections        List          Specify a comma separated list of connections to use in the session.\n",
       "    %extra_py_files     List          Comma separated list of additional Python files From S3.\n",
       "    %extra_jars         List          Comma separated list of additional Jars to include in the cluster.\n",
       "    %spark_conf         String        Specify custom spark configurations for your session. \n",
       "                                      E.g. %spark_conf spark.serializer=org.apache.spark.serializer.KryoSerializer\n",
       "----\n",
       "                                      \n",
       "## Magic for Ray Job\n",
       "\n",
       "----\n",
       "    %min_workers        Int           The minimum number of workers that are allocated to a Ray job. \n",
       "                                      Default: 1.\n",
       "    %object_memory_head Int           The percentage of free memory on the instance head node after a warm start. \n",
       "                                      Minimum: 0. Maximum: 100.\n",
       "    %object_memory_worker Int         The percentage of free memory on the instance worker nodes after a warm start. \n",
       "                                      Minimum: 0. Maximum: 100.\n",
       "----\n",
       "\n",
       "## Action Magic\n",
       "\n",
       "----\n",
       "\n",
       "    %%sql               String        Run SQL code. All lines after the initial %%sql magic will be passed\n",
       "                                      as part of the SQL code.  \n",
       "----\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "08363097-99f3-4aa8-9ce4-a937727c979b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous Job type: glueray\n",
      "Setting new Job type to glueray\n",
      "Setting Glue version to: 3.0\n",
      "Additional python modules to be included:\n",
      "modin[ray]\n",
      "s3fs\n",
      "pyarrow\n",
      "fastparquet\n",
      "xgboost_ray\n",
      "boto3\n",
      "Setting new minimum workers: 25\n",
      "Previous number of workers: 50\n",
      "Setting new number of workers to: 25\n",
      "Setting new object_memory_worker to: 10 %\n"
     ]
    }
   ],
   "source": [
    "# %additional_python_modules xgboost==1.7.2\n",
    "%glue_ray\n",
    "%glue_version 3.0\n",
    "# %additional_python_modules xgboost,ray,xgboost_ray,pyarrow==6.0.1\n",
    "# %additional_python_modules modin,s3fs,pyarrow,fastparquet\n",
    "# %additional_python_modules pyspark,raydp\n",
    "%additional_python_modules modin[ray],s3fs,pyarrow,fastparquet,xgboost_ray,boto3\n",
    "%min_workers 25\n",
    "%number_of_workers 25\n",
    "%object_memory_worker 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "39a750d5-1775-4986-b0d7-ea2265ad8b8e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following configurations have been updated: {'__MODIN_AUTOIMPORT_PANDAS__': 1}\n"
     ]
    }
   ],
   "source": [
    "%%configure \n",
    "{\"__MODIN_AUTOIMPORT_PANDAS__\": 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1db2d8f-4afe-45bc-9eee-baf22a740741",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Authenticating with environment variables and user-defined glue_role_arn: arn:aws:iam::795321850195:role/service-role/AmazonSageMaker-ExecutionRole-20221201T150970\n",
      "Trying to create a Glue session for the kernel.\n",
      "Worker Type: Z.2X\n",
      "Number of Workers: 25\n",
      "Session ID: 8ae8751b-ea1a-4458-a70e-1441ac320283\n",
      "Job Type: glueray\n",
      "Applying the following default arguments:\n",
      "--glue_kernel_version 0.37.0\n",
      "--enable-glue-datacatalog true\n",
      "--__MODIN_AUTOIMPORT_PANDAS__ 1\n",
      "--auto-scaling-ray-min-workers 25\n",
      "--additional-python-modules modin[ray],s3fs,pyarrow,fastparquet,xgboost_ray,boto3\n",
      "--object_store_memory_worker 10\n",
      "Waiting for session 8ae8751b-ea1a-4458-a70e-1441ac320283 to get into ready status...\n",
      "Session 8ae8751b-ea1a-4458-a70e-1441ac320283 has been created.\n",
      "3.9.14 (main, Oct 22 2022, 00:08:38) \n",
      "[GCC 7.3.1 20180712 (Red Hat 7.3.1-15)]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95ced67c-15e2-4a91-b461-5d0d95181d18",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "def list_s3_files_in_folder_using_client(bucket_name, prefix):\n",
    "    \"\"\"\n",
    "    This function will list down all files in a folder from S3 bucket\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    s3_client = boto3.client(\"s3\")\n",
    "    # bucket_name = \"testbucket-frompython-2\"\n",
    "    response = s3_client.list_objects_v2(Bucket=bucket_name, Prefix=prefix)\n",
    "    files = response.get(\"Contents\")\n",
    "    for file in files:\n",
    "        print(f\"file_name: {file['Key']}, size: {(file['Size']/1_000_000):,} MB\")\n",
    "    return files\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b8c50f80-7014-4017-ba73-08e344ef20ea",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file_name: nyc-taxi-orig-cleaned-split-parquet-per-year/ride-fare/year=2012/part-00000-tid-4629508899230787795-13cdd6fc-f68a-4bbe-a8d9-b1f89f5baabd-1054-1.c000.parquet, size: 2,439.928492 MB\n",
      "file_name: nyc-taxi-orig-cleaned-split-parquet-per-year/ride-fare/year=2013/part-00000-tid-4629508899230787795-13cdd6fc-f68a-4bbe-a8d9-b1f89f5baabd-1054-2.c000.parquet, size: 2,385.036466 MB\n",
      "file_name: nyc-taxi-orig-cleaned-split-parquet-per-year/ride-fare/year=2014/part-00000-tid-4629508899230787795-13cdd6fc-f68a-4bbe-a8d9-b1f89f5baabd-1054-3.c000.parquet, size: 2,280.406509 MB\n",
      "file_name: nyc-taxi-orig-cleaned-split-parquet-per-year/ride-fare/year=2015/part-00000-tid-4629508899230787795-13cdd6fc-f68a-4bbe-a8d9-b1f89f5baabd-1054-4.c000.parquet, size: 2,047.517981 MB\n",
      "file_name: nyc-taxi-orig-cleaned-split-parquet-per-year/ride-fare/year=2016/part-00000-tid-4629508899230787795-13cdd6fc-f68a-4bbe-a8d9-b1f89f5baabd-1054-5.c000.parquet, size: 1,835.207416 MB\n",
      "file_name: nyc-taxi-orig-cleaned-split-parquet-per-year/ride-fare/year=2017/part-00000-tid-4629508899230787795-13cdd6fc-f68a-4bbe-a8d9-b1f89f5baabd-1054-6.c000.parquet, size: 1,585.392645 MB\n",
      "file_name: nyc-taxi-orig-cleaned-split-parquet-per-year/ride-fare/year=2018/part-00000-tid-4629508899230787795-13cdd6fc-f68a-4bbe-a8d9-b1f89f5baabd-1054-7.c000.parquet, size: 1,442.322029 MB\n",
      "file_name: nyc-taxi-orig-cleaned-split-parquet-per-year/ride-fare/year=2019/part-00000-tid-4629508899230787795-13cdd6fc-f68a-4bbe-a8d9-b1f89f5baabd-1054-8.c000.parquet, size: 636.961384 MB\n",
      "file_name: nyc-taxi-orig-cleaned-split-parquet-per-year/ride-info/year=2012/part-00000-tid-3325758054719273621-f557a9df-d255-4241-bc37-5c43869c3044-879-1.c000.parquet, size: 6,070.396965 MB\n",
      "file_name: nyc-taxi-orig-cleaned-split-parquet-per-year/ride-info/year=2013/part-00000-tid-3325758054719273621-f557a9df-d255-4241-bc37-5c43869c3044-879-2.c000.parquet, size: 5,835.753117 MB\n",
      "file_name: nyc-taxi-orig-cleaned-split-parquet-per-year/ride-info/year=2014/part-00000-tid-3325758054719273621-f557a9df-d255-4241-bc37-5c43869c3044-879-3.c000.parquet, size: 5,536.621354 MB\n",
      "file_name: nyc-taxi-orig-cleaned-split-parquet-per-year/ride-info/year=2015/part-00000-tid-3325758054719273621-f557a9df-d255-4241-bc37-5c43869c3044-879-4.c000.parquet, size: 4,909.053435 MB\n",
      "file_name: nyc-taxi-orig-cleaned-split-parquet-per-year/ride-info/year=2016/part-00000-tid-3325758054719273621-f557a9df-d255-4241-bc37-5c43869c3044-879-5.c000.parquet, size: 4,336.631869 MB\n",
      "file_name: nyc-taxi-orig-cleaned-split-parquet-per-year/ride-info/year=2017/part-00000-tid-3325758054719273621-f557a9df-d255-4241-bc37-5c43869c3044-879-6.c000.parquet, size: 3,777.817684 MB\n",
      "file_name: nyc-taxi-orig-cleaned-split-parquet-per-year/ride-info/year=2018/part-00000-tid-3325758054719273621-f557a9df-d255-4241-bc37-5c43869c3044-879-7.c000.parquet, size: 3,419.4156 MB\n",
      "file_name: nyc-taxi-orig-cleaned-split-parquet-per-year/ride-info/year=2019/part-00000-tid-3325758054719273621-f557a9df-d255-4241-bc37-5c43869c3044-879-8.c000.parquet, size: 1,482.490261 MB\n"
     ]
    }
   ],
   "source": [
    "s3_files = list_s3_files_in_folder_using_client('dsoaws', 'nyc-taxi-orig-cleaned-split-parquet-per-year/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5931d21c-d69a-4995-9980-73b73bcda6cb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModuleNotFoundError: No module named 'modin'\n"
     ]
    }
   ],
   "source": [
    "# Import ray and initialize a local Ray cluster.\n",
    "import modin.pandas as pd\n",
    "import ray\n",
    "\n",
    "ray.init(address=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6214e5fa-551f-4815-9757-049a1aa41cce",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'Key': 'nyc-taxi-orig-cleaned-split-parquet-per-year/ride-fare/year=2012/part-00000-tid-4629508899230787795-13cdd6fc-f68a-4bbe-a8d9-b1f89f5baabd-1054-1.c000.parquet', 'LastModified': datetime.datetime(2023, 1, 3, 20, 31, 2, tzinfo=tzlocal()), 'ETag': '\"bfb933241c734d3dbcaf5e1d2dc2984e-291\"', 'Size': 2439928492, 'StorageClass': 'STANDARD'}, {'Key': 'nyc-taxi-orig-cleaned-split-parquet-per-year/ride-fare/year=2013/part-00000-tid-4629508899230787795-13cdd6fc-f68a-4bbe-a8d9-b1f89f5baabd-1054-2.c000.parquet', 'LastModified': datetime.datetime(2023, 1, 3, 20, 31, 41, tzinfo=tzlocal()), 'ETag': '\"00c8b377ab20e00718ab97b3ddf3101a-285\"', 'Size': 2385036466, 'StorageClass': 'STANDARD'}, {'Key': 'nyc-taxi-orig-cleaned-split-parquet-per-year/ride-fare/year=2014/part-00000-tid-4629508899230787795-13cdd6fc-f68a-4bbe-a8d9-b1f89f5baabd-1054-3.c000.parquet', 'LastModified': datetime.datetime(2023, 1, 3, 20, 31, 41, tzinfo=tzlocal()), 'ETag': '\"e117aaf3141594e31680a2e8a92299ba-272\"', 'Size': 2280406509, 'StorageClass': 'STANDARD'}, {'Key': 'nyc-taxi-orig-cleaned-split-parquet-per-year/ride-fare/year=2015/part-00000-tid-4629508899230787795-13cdd6fc-f68a-4bbe-a8d9-b1f89f5baabd-1054-4.c000.parquet', 'LastModified': datetime.datetime(2023, 1, 3, 20, 31, 23, tzinfo=tzlocal()), 'ETag': '\"7f57b1c8ec89cfc1cc13e4084ce5056b-245\"', 'Size': 2047517981, 'StorageClass': 'STANDARD'}, {'Key': 'nyc-taxi-orig-cleaned-split-parquet-per-year/ride-fare/year=2016/part-00000-tid-4629508899230787795-13cdd6fc-f68a-4bbe-a8d9-b1f89f5baabd-1054-5.c000.parquet', 'LastModified': datetime.datetime(2023, 1, 3, 20, 31, 33, tzinfo=tzlocal()), 'ETag': '\"b0e77ce2814449580f979d2c64782359-219\"', 'Size': 1835207416, 'StorageClass': 'STANDARD'}, {'Key': 'nyc-taxi-orig-cleaned-split-parquet-per-year/ride-fare/year=2017/part-00000-tid-4629508899230787795-13cdd6fc-f68a-4bbe-a8d9-b1f89f5baabd-1054-6.c000.parquet', 'LastModified': datetime.datetime(2023, 1, 3, 20, 31, 15, tzinfo=tzlocal()), 'ETag': '\"8a1c7d08b95944c28f45064d5f6a3039-189\"', 'Size': 1585392645, 'StorageClass': 'STANDARD'}, {'Key': 'nyc-taxi-orig-cleaned-split-parquet-per-year/ride-fare/year=2018/part-00000-tid-4629508899230787795-13cdd6fc-f68a-4bbe-a8d9-b1f89f5baabd-1054-7.c000.parquet', 'LastModified': datetime.datetime(2023, 1, 3, 20, 31, 45, tzinfo=tzlocal()), 'ETag': '\"4e56a851f40e5ed5b8fcc5e347ef0211-172\"', 'Size': 1442322029, 'StorageClass': 'STANDARD'}, {'Key': 'nyc-taxi-orig-cleaned-split-parquet-per-year/ride-fare/year=2019/part-00000-tid-4629508899230787795-13cdd6fc-f68a-4bbe-a8d9-b1f89f5baabd-1054-8.c000.parquet', 'LastModified': datetime.datetime(2023, 1, 3, 20, 31, 45, tzinfo=tzlocal()), 'ETag': '\"9d7f6c437495af7e9ac749e39058979d-76\"', 'Size': 636961384, 'StorageClass': 'STANDARD'}, {'Key': 'nyc-taxi-orig-cleaned-split-parquet-per-year/ride-info/year=2012/part-00000-tid-3325758054719273621-f557a9df-d255-4241-bc37-5c43869c3044-879-1.c000.parquet', 'LastModified': datetime.datetime(2023, 1, 3, 20, 31, 45, tzinfo=tzlocal()), 'ETag': '\"cb75dcb3f4da6a8ba2796f2b94cb828a-724\"', 'Size': 6070396965, 'StorageClass': 'STANDARD'}, {'Key': 'nyc-taxi-orig-cleaned-split-parquet-per-year/ride-info/year=2013/part-00000-tid-3325758054719273621-f557a9df-d255-4241-bc37-5c43869c3044-879-2.c000.parquet', 'LastModified': datetime.datetime(2023, 1, 3, 20, 32, 2, tzinfo=tzlocal()), 'ETag': '\"23bbd921954af65b9d77a51f7d3f5f7d-696\"', 'Size': 5835753117, 'StorageClass': 'STANDARD'}, {'Key': 'nyc-taxi-orig-cleaned-split-parquet-per-year/ride-info/year=2014/part-00000-tid-3325758054719273621-f557a9df-d255-4241-bc37-5c43869c3044-879-3.c000.parquet', 'LastModified': datetime.datetime(2023, 1, 3, 20, 32, 24, tzinfo=tzlocal()), 'ETag': '\"e8abe6990c7952527672bbd2ad4e9a23-661\"', 'Size': 5536621354, 'StorageClass': 'STANDARD'}, {'Key': 'nyc-taxi-orig-cleaned-split-parquet-per-year/ride-info/year=2015/part-00000-tid-3325758054719273621-f557a9df-d255-4241-bc37-5c43869c3044-879-4.c000.parquet', 'LastModified': datetime.datetime(2023, 1, 3, 20, 32, 34, tzinfo=tzlocal()), 'ETag': '\"3537d39794ae91ca661973829bd3a3c6-586\"', 'Size': 4909053435, 'StorageClass': 'STANDARD'}, {'Key': 'nyc-taxi-orig-cleaned-split-parquet-per-year/ride-info/year=2016/part-00000-tid-3325758054719273621-f557a9df-d255-4241-bc37-5c43869c3044-879-5.c000.parquet', 'LastModified': datetime.datetime(2023, 1, 3, 20, 32, 48, tzinfo=tzlocal()), 'ETag': '\"b8412daeeb496d6ed450414777d9edd7-517\"', 'Size': 4336631869, 'StorageClass': 'STANDARD'}, {'Key': 'nyc-taxi-orig-cleaned-split-parquet-per-year/ride-info/year=2017/part-00000-tid-3325758054719273621-f557a9df-d255-4241-bc37-5c43869c3044-879-6.c000.parquet', 'LastModified': datetime.datetime(2023, 1, 3, 20, 34, 23, tzinfo=tzlocal()), 'ETag': '\"7c8186ad066ec4c96bd7d1657fb4352d-451\"', 'Size': 3777817684, 'StorageClass': 'STANDARD'}, {'Key': 'nyc-taxi-orig-cleaned-split-parquet-per-year/ride-info/year=2018/part-00000-tid-3325758054719273621-f557a9df-d255-4241-bc37-5c43869c3044-879-7.c000.parquet', 'LastModified': datetime.datetime(2023, 1, 3, 20, 34, 31, tzinfo=tzlocal()), 'ETag': '\"4efc0ff350b9dfe45d449bf0da824415-408\"', 'Size': 3419415600, 'StorageClass': 'STANDARD'}, {'Key': 'nyc-taxi-orig-cleaned-split-parquet-per-year/ride-info/year=2019/part-00000-tid-3325758054719273621-f557a9df-d255-4241-bc37-5c43869c3044-879-8.c000.parquet', 'LastModified': datetime.datetime(2023, 1, 3, 20, 34, 35, tzinfo=tzlocal()), 'ETag': '\"8d2f4611cb3e2f2c494ef417dd60a2b4-177\"', 'Size': 1482490261, 'StorageClass': 'STANDARD'}]\n"
     ]
    }
   ],
   "source": [
    "s3_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6023bb91-55d8-493b-972f-62995441c706",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: When using a pre-initialized Ray cluster, please ensure that the runtime env sets environment variable __MODIN_AUTOIMPORT_PANDAS__ to 1\n"
     ]
    }
   ],
   "source": [
    "# ds_fare = ray.data.read_parquet([\"s3://dsoaws/nyc-taxi-orig-cleaned-split-parquet-per-year/ride-fare/year=2019\"])\n",
    "# df_fare = pd.read_parquet(\"s3://dsoaws/nyc-taxi-orig-cleaned-split-parquet-per-year/ride-fare/year=2019/part-00000-tid-4629508899230787795-13cdd6fc-f68a-4bbe-a8d9-b1f89f5baabd-1054-8.c000.parquet\")\n",
    "\n",
    "# Modin does not support reading recursively\n",
    "df_fare = pd.concat([pd.read_parquet(f's3://dsoaws/{file[\"Key\"]}') for file in s3_files if ('year=2019' in file['Key'] and 'ride-fare' in file['Key'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "75240a7c-5764-45b0-aa3f-bfa2004c95cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# df_fare = pd.read_parquet(\"s3://dsoaws/nyc-taxi-orig-cleaned-split-parquet-per-year/ride-fare/year=2018\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e56a1a69-98e1-4683-854e-1974cbb33fb8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ride_id         44200708\n",
      "payment_type    44200708\n",
      "fare_amount     44200708\n",
      "extra           44200708\n",
      "mta_tax         44200708\n",
      "tip_amount      44200708\n",
      "tolls_amount    44200708\n",
      "total_amount    44200708\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df_fare.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d5236ece-e780-427f-83e3-8e0f4a0bc034",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                ride_id  payment_type  ...  tolls_amount  total_amount\n",
      "0         1400160115693             2  ...          6.12     40.419998\n",
      "1         1331440326117             1  ...          0.00     12.950000\n",
      "2         3770982177323             1  ...          0.00      9.000000\n",
      "3         2834679003335             1  ...          0.00      9.960000\n",
      "4         1400160115694             1  ...          0.00     24.959999\n",
      "...                 ...           ...  ...           ...           ...\n",
      "44200703  1417341801945             1  ...          0.00     12.800000\n",
      "44200704  1417341801946             2  ...          0.00     16.299999\n",
      "44200705  1417341801947             1  ...          0.00     11.760000\n",
      "44200706  1417341801948             1  ...          0.00     32.750000\n",
      "44200707  1417341801949             1  ...          6.12     31.100000\n",
      "\n",
      "[44200708 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "df_fare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ad669ca1-d8ce-4c02-b4a8-0986bb1effb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f\"The dataset (ride-fare) has {ds_fare.count():,} rows.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fa4d141b-95ac-484e-99be-388d0921af7b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # In order to get the in-memory size, we can trigger full reading of the dataset and inspect the size in bytes.\n",
    "# print(f'The dataset (ride-fare) used {(ds_fare.fully_executed().size_bytes()/1_000_000_000):,} GBs.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "84e7b141-ab6e-4d8d-b6b2-fecc2b08cb8c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Mondi does not support reading recursively\n",
    "df_info = pd.concat([pd.read_parquet(f's3://dsoaws/{file[\"Key\"]}') for file in s3_files if ('year=2019' in file['Key'] and 'ride-info' in file['Key'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3d192315-1bf7-4e1e-8f5a-7dc6d7cedaf2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                ride_id  vendor_id  ...  rate_code_id store_and_fwd_flag\n",
      "0         3831112935408          2  ...             1                  N\n",
      "1         1005022516111          1  ...             1                  N\n",
      "2         1391571392713          2  ...             1                  N\n",
      "3          944893098665          2  ...             3                  N\n",
      "4         3831112935409          2  ...             1                  N\n",
      "...                 ...        ...  ...           ...                ...\n",
      "44200703  1331441272707          1  ...             1                  N\n",
      "44200704  2834679949925          1  ...             1                  N\n",
      "44200705  1331441272708          1  ...             1                  N\n",
      "44200706  2834679949926          2  ...             1                  N\n",
      "44200707  1331441272709          1  ...             1                  N\n",
      "\n",
      "[44200708 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "df_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "837c65a6-b458-4bbc-a839-0804fbe18c8e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                ride_id  payment_type  ...  rate_code_id  store_and_fwd_flag\n",
      "0         1400160115693             2  ...             1                   N\n",
      "1         1331440326117             1  ...             1                   N\n",
      "2         3770982177323             1  ...             1                   N\n",
      "3         2834679003335             1  ...             1                   N\n",
      "4         1400160115694             1  ...             1                   N\n",
      "...                 ...           ...  ...           ...                 ...\n",
      "44200703  1417341801945             1  ...             1                   N\n",
      "44200704  1417341801946             2  ...             1                   N\n",
      "44200705  1417341801947             1  ...             1                   N\n",
      "44200706  1417341801948             1  ...             1                   N\n",
      "44200707  1417341801949             1  ...             1                   N\n",
      "\n",
      "[44200708 rows x 15 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[33m(raylet, ip=169.254.1.2)\u001b[0m /opt/amazon/python3.9-ray/lib/python3.9/site-packages/ray/dashboard/modules/reporter/reporter_agent.py:46: UserWarning: `gpustat` package is not installed. GPU monitoring is not available. To have full functionality of the dashboard please install `pip install ray[default]`.)\n",
      "\u001b[2m\u001b[33m(raylet, ip=169.254.1.2)\u001b[0m   warnings.warn(\n",
      "\u001b[2m\u001b[33m(raylet, ip=169.254.1.2)\u001b[0m /opt/amazon/python3.9-ray/lib/python3.9/site-packages/ray/dashboard/modules/reporter/reporter_agent.py:46: UserWarning: `gpustat` package is not installed. GPU monitoring is not available. To have full functionality of the dashboard please install `pip install ray[default]`.)\n",
      "\u001b[2m\u001b[33m(raylet, ip=169.254.1.2)\u001b[0m   warnings.warn(\n",
      "\u001b[2m\u001b[33m(raylet, ip=169.254.1.2)\u001b[0m /opt/amazon/python3.9-ray/lib/python3.9/site-packages/ray/dashboard/modules/reporter/reporter_agent.py:46: UserWarning: `gpustat` package is not installed. GPU monitoring is not available. To have full functionality of the dashboard please install `pip install ray[default]`.)\n",
      "\u001b[2m\u001b[33m(raylet, ip=169.254.1.2)\u001b[0m   warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Join data based on ride_id\n",
    "df = df_fare.merge(df_info, on='ride_id', how='left')\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "86e43e93-c03e-4082-a266-0b5842977812",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ride_id               44200708\n",
      "payment_type          44200708\n",
      "fare_amount           44200708\n",
      "extra                 44200708\n",
      "mta_tax               44200708\n",
      "tip_amount            44200708\n",
      "tolls_amount          44200708\n",
      "total_amount          44200708\n",
      "vendor_id             44200708\n",
      "passenger_count       44200708\n",
      "pickup_at             44200708\n",
      "dropoff_at            44200708\n",
      "trip_distance         44200708\n",
      "rate_code_id          44200708\n",
      "store_and_fwd_flag    44200708\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a111bc-5b93-4c88-a27c-339c5cf68df0",
   "metadata": {},
   "source": [
    "## Preprocess data\n",
    "\n",
    "The goal is to predict the `total_amount` (typically called the `fare`) of each ride.  To simplify the pre-processing, we may want to drop certain features like `pickup_at` and `dropoff_at` since taxi fares do not depend on the time of day, typically (unlike ride-share fares like Uber and Lyft).\n",
    "\n",
    "We may also want to drop unused fields like `store_and_fwd_flag` which is an edge case where the taxi-meter was disconnected during the trip.  This should not impact the fare.\n",
    "\n",
    "TODO:  Describe why we should drop the `rate_code_id` - or otherwise explain how it could be used.\n",
    "\n",
    "Lastly, the `payment_type` are not useful for this predictive model as the fare should not depend on how the user is paying."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "63bdcfac-918e-4030-bc8d-adeea19afcaf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset(num_blocks=5, num_rows=44200708, schema={ride_id: int64, payment_type: int32, fare_amount: float32, extra: float32, mta_tax: float32, tip_amount: float32, tolls_amount: float32, total_amount: float32, vendor_id: int32, passenger_count: int8, pickup_at: datetime64[ns], dropoff_at: datetime64[ns], trip_distance: float32, rate_code_id: int32, store_and_fwd_flag: object})\n"
     ]
    }
   ],
   "source": [
    "# Create ray dataset:\n",
    "ds = ray.data.from_modin(df)\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a1785473-b897-47bd-9e42-5ebe6238aa93",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# #Count of null for all columns\n",
    "# isnull = df.isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6fb34c52-6799-4e35-94c6-62b640dfcf9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map_Batches: 100%|##########| 5/5 [00:08<00:00,  1.79s/it]\n"
     ]
    }
   ],
   "source": [
    "# Data type timestamp of column pickup_at is not supported.\n",
    "# Data type timestamp of column dropoff_at is not supported.\n",
    "# Data type string of column rate_code_id is not supported.\n",
    "# Data type string of column store_and_fwd_flag is not supported.\n",
    "# Data type string of column payment_type is not supported.\n",
    "\n",
    "# Drop the following columns because xgboost training gave errors\n",
    "ds = ds.drop_columns([\"pickup_at\", \"dropoff_at\", \"store_and_fwd_flag\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "938e752a-10dc-4637-81f2-a5f50b606089",
   "metadata": {},
   "source": [
    "#### Split data into training and test sets\n",
    "\n",
    "Randomly split data into training and test sets. By doing this, you can train and tune the model using only the training subset, and then evaluate the model's performance on the test set to get a sense of how the model will perform on new data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8562adc9-b83c-45e8-a623-db72797e3e5d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset(num_blocks=5, num_rows=44200708, schema={ride_id: int64, payment_type: int32, fare_amount: float32, extra: float32, mta_tax: float32, tip_amount: float32, tolls_amount: float32, total_amount: float32, vendor_id: int32, passenger_count: int8, trip_distance: float32, rate_code_id: int32})\n"
     ]
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "df035902-5aeb-44e9-8615-91eb057a693d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[33m(raylet, ip=169.254.1.2)\u001b[0m /opt/amazon/python3.9-ray/lib/python3.9/site-packages/ray/dashboard/modules/reporter/reporter_agent.py:46: UserWarning: `gpustat` package is not installed. GPU monitoring is not available. To have full functionality of the dashboard please install `pip install ray[default]`.)\n",
      "\u001b[2m\u001b[33m(raylet, ip=169.254.1.2)\u001b[0m   warnings.warn(\n",
      "\u001b[2m\u001b[33m(raylet, ip=169.254.1.2)\u001b[0m /opt/amazon/python3.9-ray/lib/python3.9/site-packages/ray/dashboard/modules/reporter/reporter_agent.py:46: UserWarning: `gpustat` package is not installed. GPU monitoring is not available. To have full functionality of the dashboard please install `pip install ray[default]`.)\n",
      "\u001b[2m\u001b[33m(raylet, ip=169.254.1.2)\u001b[0m   warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the dataset randomly into 70% for training and 30% for testing. Passing a seed for deterministic behavior\n",
    "# Split data into train and validation.\n",
    "train_dataset, valid_dataset = ds.train_test_split(test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ab56b27e-dc1f-4033-9b86-82667f42f67f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset(num_blocks=4, num_rows=30940495, schema={ride_id: int64, payment_type: int32, fare_amount: float32, extra: float32, mta_tax: float32, tip_amount: float32, tolls_amount: float32, total_amount: float32, vendor_id: int32, passenger_count: int8, trip_distance: float32, rate_code_id: int32})\n"
     ]
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e5e5d3e-1b3e-433b-96ae-0d049b9eb5ce",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Visualize the data\n",
    "You can plot the data to explore it visually. The following plot shows the number of bicycle rentals during each hour of the day.  As you might expect, rentals are low during the night, and peak at commute hours.  \n",
    "\n",
    "To create plots, call `display()` on a DataFrame in Databricks and click the plot icon below the table.\n",
    "\n",
    "To create the plot shown, run the command in the following cell. The results appear in a table. From the drop-down menu below the table, select \"Line\". Click **Plot Options...**. In the dialog, drag `hr` to the **Keys** field, and drag `cnt` to the **Values** field. Also in the **Keys** field, click the \"x\" next to `<id>` to remove it. In the **Aggregation** drop down, select \"AVG\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "990a103e-55af-49c4-8d1b-e52eddba5a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train.select(\"passenger_count\", \"total_amount\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94f7818e-a114-411e-a01d-a1409b6d992e",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "290cf446-dd9f-4ea1-990d-56cee25ff44e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "\n",
    "# def get_input_matrix(df):\n",
    "#     return np.column_stack((df.trip_distance, np.ones(df.count())))\n",
    "\n",
    "# train_X = get_input_matrix(train)\n",
    "# train_y = np.array(train['total_amount'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c49e01a9-387b-4b9c-a321-c0e0351e689b",
   "metadata": {},
   "source": [
    "## Train the machine learning pipeline\n",
    "\n",
    "Now that you have reviewed the data and prepared it as a DataFrame with numeric values, you're ready to train a model to predict future bike sharing rentals. \n",
    "\n",
    "Most MLlib algorithms require a single input column containing a vector of features and a single target column. The DataFrame currently has one column for each feature. MLlib provides functions to help you prepare the dataset in the required format.\n",
    "\n",
    "MLlib pipelines combine multiple steps into a single workflow, making it easier to iterate as you develop the model. \n",
    "\n",
    "In this example, you create a pipeline using the following functions:\n",
    "* `VectorAssembler`: Assembles the feature columns into a feature vector.\n",
    "* `VectorIndexer`: Identifies columns that should be treated as categorical. This is done heuristically, identifying any column with a small number of distinct values as categorical.\n",
    "* `SparkXGBRegressor`: Uses the [SparkXGBRegressor](https://xgboost.readthedocs.io/en/stable/python/python_api.html#xgboost.spark.SparkXGBRegressor) estimator to learn how to predict the fare from the feature vectors.\n",
    "* `CrossValidator`: The XGBoost regression algorithm has several hyperparameters. This notebook illustrates how to use [hyperparameter tuning in Spark](https://spark.apache.org/docs/latest/ml-tuning.html). This capability automatically tests a grid of hyperparameters and chooses the best resulting model.\n",
    "\n",
    "For more information:  \n",
    "[VectorAssembler](https://spark.apache.org/docs/latest/ml-features.html#vectorassembler)  \n",
    "[VectorIndexer](https://spark.apache.org/docs/latest/ml-features.html#vectorindexer)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b70471f4-5d8c-4142-a4c5-00196add66a4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2023-01-11 00:45:02 (running for 00:00:03.08)\n",
      "Memory usage on this node: 19.3/62.9 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 150.0/200 CPUs, 0/0 GPUs, 0.0/1089.27 GiB heap, 0.0/469.5 GiB objects\n",
      "Result logdir: /tmp/ray_results/XGBoostTrainer_2023-01-11_00-44-59\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+----------------------------+----------+--------------------------------------------+\n",
      "| Trial name                 | status   | loc                                        |\n",
      "|----------------------------+----------+--------------------------------------------|\n",
      "| XGBoostTrainer_2ce59_00000 | RUNNING  | 2600:1f16:ca4:7a08:7359:4a6:809c:4f23:2139 |\n",
      "+----------------------------+----------+--------------------------------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-01-11 00:45:07 (running for 00:00:08.08)\n",
      "Memory usage on this node: 20.0/62.9 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 150.0/200 CPUs, 0/0 GPUs, 0.0/1089.27 GiB heap, 0.0/469.5 GiB objects\n",
      "Result logdir: /tmp/ray_results/XGBoostTrainer_2023-01-11_00-44-59\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+----------------------------+----------+--------------------------------------------+\n",
      "| Trial name                 | status   | loc                                        |\n",
      "|----------------------------+----------+--------------------------------------------|\n",
      "| XGBoostTrainer_2ce59_00000 | RUNNING  | 2600:1f16:ca4:7a08:7359:4a6:809c:4f23:2139 |\n",
      "+----------------------------+----------+--------------------------------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-01-11 00:45:12 (running for 00:00:13.08)\n",
      "Memory usage on this node: 20.0/62.9 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 150.0/200 CPUs, 0/0 GPUs, 0.0/1089.27 GiB heap, 0.0/469.5 GiB objects\n",
      "Result logdir: /tmp/ray_results/XGBoostTrainer_2023-01-11_00-44-59\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+----------------------------+----------+--------------------------------------------+\n",
      "| Trial name                 | status   | loc                                        |\n",
      "|----------------------------+----------+--------------------------------------------|\n",
      "| XGBoostTrainer_2ce59_00000 | RUNNING  | 2600:1f16:ca4:7a08:7359:4a6:809c:4f23:2139 |\n",
      "+----------------------------+----------+--------------------------------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-01-11 00:45:17 (running for 00:00:18.09)\n",
      "Memory usage on this node: 20.0/62.9 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 150.0/200 CPUs, 0/0 GPUs, 0.0/1089.27 GiB heap, 0.0/469.5 GiB objects\n",
      "Result logdir: /tmp/ray_results/XGBoostTrainer_2023-01-11_00-44-59\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+----------------------------+----------+--------------------------------------------+\n",
      "| Trial name                 | status   | loc                                        |\n",
      "|----------------------------+----------+--------------------------------------------|\n",
      "| XGBoostTrainer_2ce59_00000 | RUNNING  | 2600:1f16:ca4:7a08:7359:4a6:809c:4f23:2139 |\n",
      "+----------------------------+----------+--------------------------------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-01-11 00:45:22 (running for 00:00:23.09)\n",
      "Memory usage on this node: 20.0/62.9 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 150.0/200 CPUs, 0/0 GPUs, 0.0/1089.27 GiB heap, 0.0/469.5 GiB objects\n",
      "Result logdir: /tmp/ray_results/XGBoostTrainer_2023-01-11_00-44-59\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+----------------------------+----------+--------------------------------------------+\n",
      "| Trial name                 | status   | loc                                        |\n",
      "|----------------------------+----------+--------------------------------------------|\n",
      "| XGBoostTrainer_2ce59_00000 | RUNNING  | 2600:1f16:ca4:7a08:7359:4a6:809c:4f23:2139 |\n",
      "+----------------------------+----------+--------------------------------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-01-11 00:45:27 (running for 00:00:28.09)\n",
      "Memory usage on this node: 20.0/62.9 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 150.0/200 CPUs, 0/0 GPUs, 0.0/1089.27 GiB heap, 0.0/469.5 GiB objects\n",
      "Result logdir: /tmp/ray_results/XGBoostTrainer_2023-01-11_00-44-59\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+----------------------------+----------+--------------------------------------------+\n",
      "| Trial name                 | status   | loc                                        |\n",
      "|----------------------------+----------+--------------------------------------------|\n",
      "| XGBoostTrainer_2ce59_00000 | RUNNING  | 2600:1f16:ca4:7a08:7359:4a6:809c:4f23:2139 |\n",
      "+----------------------------+----------+--------------------------------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-01-11 00:45:32 (running for 00:00:33.10)\n",
      "Memory usage on this node: 20.0/62.9 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 150.0/200 CPUs, 0/0 GPUs, 0.0/1089.27 GiB heap, 0.0/469.5 GiB objects\n",
      "Result logdir: /tmp/ray_results/XGBoostTrainer_2023-01-11_00-44-59\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+----------------------------+----------+--------------------------------------------+\n",
      "| Trial name                 | status   | loc                                        |\n",
      "|----------------------------+----------+--------------------------------------------|\n",
      "| XGBoostTrainer_2ce59_00000 | RUNNING  | 2600:1f16:ca4:7a08:7359:4a6:809c:4f23:2139 |\n",
      "+----------------------------+----------+--------------------------------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-01-11 00:45:37 (running for 00:00:38.10)\n",
      "Memory usage on this node: 20.0/62.9 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 150.0/200 CPUs, 0/0 GPUs, 0.0/1089.27 GiB heap, 0.0/469.5 GiB objects\n",
      "Result logdir: /tmp/ray_results/XGBoostTrainer_2023-01-11_00-44-59\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+----------------------------+----------+--------------------------------------------+\n",
      "| Trial name                 | status   | loc                                        |\n",
      "|----------------------------+----------+--------------------------------------------|\n",
      "| XGBoostTrainer_2ce59_00000 | RUNNING  | 2600:1f16:ca4:7a08:7359:4a6:809c:4f23:2139 |\n",
      "+----------------------------+----------+--------------------------------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-01-11 00:45:42 (running for 00:00:43.10)\n",
      "Memory usage on this node: 19.9/62.9 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 150.0/200 CPUs, 0/0 GPUs, 0.0/1089.27 GiB heap, 0.0/469.5 GiB objects\n",
      "Result logdir: /tmp/ray_results/XGBoostTrainer_2023-01-11_00-44-59\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+----------------------------+----------+--------------------------------------------+\n",
      "| Trial name                 | status   | loc                                        |\n",
      "|----------------------------+----------+--------------------------------------------|\n",
      "| XGBoostTrainer_2ce59_00000 | RUNNING  | 2600:1f16:ca4:7a08:7359:4a6:809c:4f23:2139 |\n",
      "+----------------------------+----------+--------------------------------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-01-11 00:45:47 (running for 00:00:48.11)\n",
      "Memory usage on this node: 20.0/62.9 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 150.0/200 CPUs, 0/0 GPUs, 0.0/1089.27 GiB heap, 0.0/469.5 GiB objects\n",
      "Result logdir: /tmp/ray_results/XGBoostTrainer_2023-01-11_00-44-59\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+----------------------------+----------+--------------------------------------------+\n",
      "| Trial name                 | status   | loc                                        |\n",
      "|----------------------------+----------+--------------------------------------------|\n",
      "| XGBoostTrainer_2ce59_00000 | RUNNING  | 2600:1f16:ca4:7a08:7359:4a6:809c:4f23:2139 |\n",
      "+----------------------------+----------+--------------------------------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-01-11 00:45:52 (running for 00:00:53.11)\n",
      "Memory usage on this node: 20.3/62.9 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 150.0/200 CPUs, 0/0 GPUs, 0.0/1089.27 GiB heap, 0.0/469.5 GiB objects\n",
      "Result logdir: /tmp/ray_results/XGBoostTrainer_2023-01-11_00-44-59\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+----------------------------+----------+--------------------------------------------+\n",
      "| Trial name                 | status   | loc                                        |\n",
      "|----------------------------+----------+--------------------------------------------|\n",
      "| XGBoostTrainer_2ce59_00000 | RUNNING  | 2600:1f16:ca4:7a08:7359:4a6:809c:4f23:2139 |\n",
      "+----------------------------+----------+--------------------------------------------+\n",
      "\n",
      "\n",
      "Result for XGBoostTrainer_2ce59_00000:\n",
      "  date: 2023-01-11_00-45-54\n",
      "  done: false\n",
      "  experiment_id: 4c24a77e861c4f0b9bd1653f09211293\n",
      "  hostname: localhost\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 2600:1f16:ca4:7a08:7359:4a6:809c:4f23\n",
      "  pid: 2139\n",
      "  time_since_restore: 52.19023942947388\n",
      "  time_this_iter_s: 52.19023942947388\n",
      "  time_total_s: 52.19023942947388\n",
      "  timestamp: 1673397954\n",
      "  timesteps_since_restore: 0\n",
      "  train-mae: 12.769308969210183\n",
      "  train-rmse: 248.23216458768954\n",
      "  training_iteration: 1\n",
      "  trial_id: 2ce59_00000\n",
      "  valid-mae: 12.811405694475901\n",
      "  valid-rmse: 109.96702271803582\n",
      "  warmup_time: 0.006021976470947266\n",
      "  \n",
      "Result for XGBoostTrainer_2ce59_00000:\n",
      "  date: 2023-01-11_00-45-55\n",
      "  done: true\n",
      "  experiment_id: 4c24a77e861c4f0b9bd1653f09211293\n",
      "  experiment_tag: '0'\n",
      "  hostname: localhost\n",
      "  iterations_since_restore: 6\n",
      "  node_ip: 2600:1f16:ca4:7a08:7359:4a6:809c:4f23\n",
      "  pid: 2139\n",
      "  time_since_restore: 53.01198935508728\n",
      "  time_this_iter_s: 0.21094369888305664\n",
      "  time_total_s: 53.01198935508728\n",
      "  timestamp: 1673397955\n",
      "  timesteps_since_restore: 0\n",
      "  train-mae: 3.3234701436854395\n",
      "  train-rmse: 192.0697219917619\n",
      "  training_iteration: 6\n",
      "  trial_id: 2ce59_00000\n",
      "  valid-mae: 3.380347137495227\n",
      "  valid-rmse: 108.99547700913459\n",
      "  warmup_time: 0.006021976470947266\n",
      "  \n",
      "== Status ==\n",
      "Current time: 2023-01-11 00:45:58 (running for 00:00:59.71)\n",
      "Memory usage on this node: 19.8/62.9 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 0/200 CPUs, 0/0 GPUs, 0.0/1089.27 GiB heap, 0.0/469.5 GiB objects\n",
      "Result logdir: /tmp/ray_results/XGBoostTrainer_2023-01-11_00-44-59\n",
      "Number of trials: 1/1 (1 TERMINATED)\n",
      "+----------------------------+------------+--------------------------------------------+--------+------------------+--------------+-------------+--------------+\n",
      "| Trial name                 | status     | loc                                        |   iter |   total time (s) |   train-rmse |   train-mae |   valid-rmse |\n",
      "|----------------------------+------------+--------------------------------------------+--------+------------------+--------------+-------------+--------------|\n",
      "| XGBoostTrainer_2ce59_00000 | TERMINATED | 2600:1f16:ca4:7a08:7359:4a6:809c:4f23:2139 |      6 |           53.012 |       192.07 |     3.32347 |      108.995 |\n",
      "+----------------------------+------------+--------------------------------------------+--------+------------------+--------------+-------------+--------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-01-11 00:45:58 (running for 00:00:59.71)\n",
      "Memory usage on this node: 19.8/62.9 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 0/200 CPUs, 0/0 GPUs, 0.0/1089.27 GiB heap, 0.0/469.5 GiB objects\n",
      "Result logdir: /tmp/ray_results/XGBoostTrainer_2023-01-11_00-44-59\n",
      "Number of trials: 1/1 (1 TERMINATED)\n",
      "+----------------------------+------------+--------------------------------------------+--------+------------------+--------------+-------------+--------------+\n",
      "| Trial name                 | status     | loc                                        |   iter |   total time (s) |   train-rmse |   train-mae |   valid-rmse |\n",
      "|----------------------------+------------+--------------------------------------------+--------+------------------+--------------+-------------+--------------|\n",
      "| XGBoostTrainer_2ce59_00000 | TERMINATED | 2600:1f16:ca4:7a08:7359:4a6:809c:4f23:2139 |      6 |           53.012 |       192.07 |     3.32347 |      108.995 |\n",
      "+----------------------------+------------+--------------------------------------------+--------+------------------+--------------+-------------+--------------+\n",
      "\n",
      "\n",
      "{'train-rmse': 192.0697219917619, 'train-mae': 3.3234701436854395, 'valid-rmse': 108.99547700913459, 'valid-mae': 3.380347137495227, 'time_this_iter_s': 0.21094369888305664, 'done': True, 'timesteps_total': None, 'episodes_total': None, 'training_iteration': 6, 'trial_id': '2ce59_00000', 'experiment_id': '4c24a77e861c4f0b9bd1653f09211293', 'date': '2023-01-11_00-45-55', 'timestamp': 1673397955, 'time_total_s': 53.01198935508728, 'pid': 2139, 'hostname': 'localhost', 'node_ip': '2600:1f16:ca4:7a08:7359:4a6:809c:4f23', 'config': {}, 'time_since_restore': 53.01198935508728, 'timesteps_since_restore': 0, 'iterations_since_restore': 6, 'warmup_time': 0.006021976470947266, 'experiment_tag': '0'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[33m(raylet, ip=169.254.1.2)\u001b[0m /opt/amazon/python3.9-ray/lib/python3.9/site-packages/ray/dashboard/modules/reporter/reporter_agent.py:46: UserWarning: `gpustat` package is not installed. GPU monitoring is not available. To have full functionality of the dashboard please install `pip install ray[default]`.)\n",
      "\u001b[2m\u001b[33m(raylet, ip=169.254.1.2)\u001b[0m   warnings.warn(\n",
      "\u001b[2m\u001b[33m(raylet, ip=169.254.1.2)\u001b[0m /opt/amazon/python3.9-ray/lib/python3.9/site-packages/ray/dashboard/modules/reporter/reporter_agent.py:46: UserWarning: `gpustat` package is not installed. GPU monitoring is not available. To have full functionality of the dashboard please install `pip install ray[default]`.)\n",
      "\u001b[2m\u001b[33m(raylet, ip=169.254.1.2)\u001b[0m   warnings.warn(\n",
      "\u001b[2m\u001b[36m(_apply_func pid=2201, ip=169.254.1.2)\u001b[0m E0111 00:45:38.356179353    2287 chttp2_transport.cc:1103]   Received a GOAWAY with error code ENHANCE_YOUR_CALM and debug data equal to \"too_many_pings\"\n",
      "\u001b[2m\u001b[36m(_apply_func pid=2133, ip=169.254.1.2)\u001b[0m E0111 00:45:38.545816928    2213 chttp2_transport.cc:1103]   Received a GOAWAY with error code ENHANCE_YOUR_CALM and debug data equal to \"too_many_pings\"\n",
      "\u001b[2m\u001b[36m(_apply_func pid=2833, ip=169.254.1.2)\u001b[0m E0111 00:45:38.762133746    2929 chttp2_transport.cc:1103]   Received a GOAWAY with error code ENHANCE_YOUR_CALM and debug data equal to \"too_many_pings\"\n",
      "\u001b[2m\u001b[36m(_apply_func pid=2135, ip=169.254.1.2)\u001b[0m E0111 00:45:38.816175242    2210 chttp2_transport.cc:1103]   Received a GOAWAY with error code ENHANCE_YOUR_CALM and debug data equal to \"too_many_pings\"\n",
      "\u001b[2m\u001b[36m(_apply_func pid=2139, ip=169.254.1.2)\u001b[0m E0111 00:45:38.829970852    2225 chttp2_transport.cc:1103]   Received a GOAWAY with error code ENHANCE_YOUR_CALM and debug data equal to \"too_many_pings\"\n",
      "\u001b[2m\u001b[36m(_apply_func pid=2134, ip=169.254.1.2)\u001b[0m E0111 00:45:38.885864307    2191 chttp2_transport.cc:1103]   Received a GOAWAY with error code ENHANCE_YOUR_CALM and debug data equal to \"too_many_pings\"\n",
      "\u001b[2m\u001b[36m(_apply_func pid=2137, ip=169.254.1.2)\u001b[0m E0111 00:45:38.850535906    2239 chttp2_transport.cc:1103]   Received a GOAWAY with error code ENHANCE_YOUR_CALM and debug data equal to \"too_many_pings\"\n",
      "\u001b[2m\u001b[36m(_apply_func pid=2835, ip=169.254.1.2)\u001b[0m E0111 00:45:39.016934474    2911 chttp2_transport.cc:1103]   Received a GOAWAY with error code ENHANCE_YOUR_CALM and debug data equal to \"too_many_pings\"\n",
      "\u001b[2m\u001b[36m(_apply_func pid=2176, ip=169.254.1.2)\u001b[0m E0111 00:45:44.359542680    2261 chttp2_transport.cc:1103]   Received a GOAWAY with error code ENHANCE_YOUR_CALM and debug data equal to \"too_many_pings\"\n",
      "\u001b[2m\u001b[36m(_apply_func pid=2142, ip=169.254.1.2)\u001b[0m E0111 00:45:44.386782270    2262 chttp2_transport.cc:1103]   Received a GOAWAY with error code ENHANCE_YOUR_CALM and debug data equal to \"too_many_pings\"\n",
      "\u001b[2m\u001b[36m(_apply_func pid=2174, ip=169.254.1.2)\u001b[0m E0111 00:45:44.315093276    2243 chttp2_transport.cc:1103]   Received a GOAWAY with error code ENHANCE_YOUR_CALM and debug data equal to \"too_many_pings\"\n",
      "\u001b[2m\u001b[36m(_apply_func pid=2149, ip=169.254.1.2)\u001b[0m E0111 00:45:44.370026235    2236 chttp2_transport.cc:1103]   Received a GOAWAY with error code ENHANCE_YOUR_CALM and debug data equal to \"too_many_pings\"\n",
      "\u001b[2m\u001b[36m(_apply_func pid=2131, ip=169.254.1.2)\u001b[0m E0111 00:45:44.404791387    2236 chttp2_transport.cc:1103]   Received a GOAWAY with error code ENHANCE_YOUR_CALM and debug data equal to \"too_many_pings\"\n",
      "\u001b[2m\u001b[36m(_apply_func pid=3014, ip=169.254.1.2)\u001b[0m E0111 00:45:44.629081285    3084 chttp2_transport.cc:1103]   Received a GOAWAY with error code ENHANCE_YOUR_CALM and debug data equal to \"too_many_pings\"\n",
      "\u001b[2m\u001b[36m(_RemoteRayXGBoostActor pid=2140, ip=169.254.1.2)\u001b[0m [00:45:48] task [xgboost.ray]:526613169872 got new rank 0\n",
      "\u001b[2m\u001b[36m(_RemoteRayXGBoostActor pid=2564, ip=169.254.1.2)\u001b[0m [00:45:48] task [xgboost.ray]:526617810784 got new rank 1\n",
      "\u001b[2m\u001b[36m(_RemoteRayXGBoostActor pid=2228, ip=169.254.1.2)\u001b[0m [00:45:48] task [xgboost.ray]:526161086304 got new rank 2\n",
      "\u001b[2m\u001b[36m(_RemoteRayXGBoostActor pid=2652, ip=169.254.1.2)\u001b[0m [00:45:48] task [xgboost.ray]:526534960944 got new rank 3\n",
      "\u001b[2m\u001b[36m(_RemoteRayXGBoostActor pid=2146, ip=169.254.1.2)\u001b[0m [00:45:48] task [xgboost.ray]:526567540384 got new rank 4\n",
      "\u001b[2m\u001b[36m(_RemoteRayXGBoostActor pid=2140, ip=169.254.1.2)\u001b[0m [00:45:48] task [xgboost.ray]:526819067744 got new rank 5\n",
      "\u001b[2m\u001b[36m(_RemoteRayXGBoostActor pid=2175, ip=169.254.1.2)\u001b[0m [00:45:48] task [xgboost.ray]:526889485936 got new rank 6\n",
      "\u001b[2m\u001b[36m(_RemoteRayXGBoostActor pid=5903, ip=169.254.1.2)\u001b[0m [00:45:48] task [xgboost.ray]:526063105648 got new rank 7\n",
      "\u001b[2m\u001b[36m(_RemoteRayXGBoostActor pid=2136, ip=169.254.1.2)\u001b[0m [00:45:48] task [xgboost.ray]:526638102320 got new rank 8\n",
      "\u001b[2m\u001b[36m(_RemoteRayXGBoostActor pid=2405, ip=169.254.1.2)\u001b[0m [00:45:49] task [xgboost.ray]:526542833552 got new rank 9\n",
      "\u001b[2m\u001b[36m(_RemoteRayXGBoostActor pid=2138, ip=169.254.1.2)\u001b[0m [00:45:49] task [xgboost.ray]:526686127824 got new rank 10\n",
      "\u001b[2m\u001b[36m(_RemoteRayXGBoostActor pid=2364, ip=169.254.1.2)\u001b[0m [00:45:49] task [xgboost.ray]:526955046752 got new rank 11\n",
      "\u001b[2m\u001b[36m(_RemoteRayXGBoostActor pid=2626, ip=169.254.1.2)\u001b[0m [00:45:49] task [xgboost.ray]:526864361264 got new rank 12\n",
      "\u001b[2m\u001b[36m(_RemoteRayXGBoostActor pid=2677, ip=169.254.1.2)\u001b[0m [00:45:49] task [xgboost.ray]:526177781504 got new rank 13\n",
      "\u001b[2m\u001b[36m(_RemoteRayXGBoostActor pid=2531, ip=169.254.1.2)\u001b[0m [00:45:49] task [xgboost.ray]:526001108592 got new rank 14\n",
      "\u001b[2m\u001b[36m(_RemoteRayXGBoostActor pid=2653, ip=169.254.1.2)\u001b[0m [00:45:49] task [xgboost.ray]:526377396016 got new rank 15\n",
      "\u001b[2m\u001b[36m(_RemoteRayXGBoostActor pid=2929, ip=169.254.1.2)\u001b[0m [00:45:49] task [xgboost.ray]:526839158624 got new rank 16\n",
      "\u001b[2m\u001b[36m(_RemoteRayXGBoostActor pid=2137, ip=169.254.1.2)\u001b[0m [00:45:49] task [xgboost.ray]:526563034784 got new rank 17\n",
      "\u001b[2m\u001b[36m(_RemoteRayXGBoostActor pid=2785, ip=169.254.1.2)\u001b[0m [00:45:49] task [xgboost.ray]:526842304304 got new rank 19\n",
      "\u001b[2m\u001b[36m(_RemoteRayXGBoostActor pid=2137, ip=169.254.1.2)\u001b[0m [00:45:49] task [xgboost.ray]:526286055168 got new rank 18\n",
      "\u001b[2m\u001b[36m(_RemoteRayXGBoostActor pid=2307, ip=169.254.1.2)\u001b[0m [00:45:50] task [xgboost.ray]:526487623376 got new rank 20\n",
      "\u001b[2m\u001b[36m(_RemoteRayXGBoostActor pid=2252, ip=169.254.1.2)\u001b[0m [00:45:50] task [xgboost.ray]:526028826416 got new rank 21\n",
      "\u001b[2m\u001b[36m(_RemoteRayXGBoostActor pid=2521, ip=169.254.1.2)\u001b[0m [00:45:50] task [xgboost.ray]:526866716512 got new rank 22\n",
      "\u001b[2m\u001b[36m(_RemoteRayXGBoostActor pid=2279, ip=169.254.1.2)\u001b[0m [00:45:50] task [xgboost.ray]:526358787936 got new rank 23\n",
      "\u001b[2m\u001b[36m(_RemoteRayXGBoostActor pid=2141, ip=169.254.1.2)\u001b[0m [00:45:50] task [xgboost.ray]:526947522400 got new rank 24\n"
     ]
    }
   ],
   "source": [
    "from xgboost_ray import RayDMatrix, RayFileType\n",
    "from ray.train.xgboost import XGBoostTrainer\n",
    "from ray.air.config import ScalingConfig\n",
    "from ray.air.config import RunConfig\n",
    "\n",
    "num_workers = 25\n",
    "trainer = XGBoostTrainer(\n",
    "    scaling_config=ScalingConfig(\n",
    "        # Number of workers to use for data parallelism.\n",
    "        num_workers=num_workers, #int(num_workers * 8 * 0.8),\n",
    "        # Whether to use GPU acceleration.\n",
    "#        trainer_resources={\"CPU\": 0},\n",
    "        resources_per_worker={\"CPU\": 6},\n",
    "        use_gpu=False,\n",
    "        # Leave enough CPU for I/O.  80% is a good choice. \n",
    "        # (Ray will warn you if you don't leave enough CPU for I/O.)\n",
    "        _max_cpu_fraction_per_node = 0.8\n",
    "    ),\n",
    "    run_config=RunConfig(local_dir=\"/tmp/ray_results\"),\n",
    "    label_column='total_amount',\n",
    "    num_boost_round=5,\n",
    "    params={\n",
    "        # XGBoost specific params\n",
    "        \"objective\": \"reg:squarederror\",\n",
    "        \"eval_metric\": [\"rmse\", \"mae\"]\n",
    "    },\n",
    "    datasets={\"train\": train_dataset, \"valid\": valid_dataset},\n",
    ")\n",
    "\n",
    "result = trainer.fit()\n",
    "print(result.metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff1338e9-3b0a-4d12-96fe-a52f21df456d",
   "metadata": {
    "tags": []
   },
   "source": [
    "The first step is to create the VectorAssembler and VectorIndexer steps. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2756047-dd80-4d91-8b98-0c0c945f971e",
   "metadata": {},
   "source": [
    "Next, define the model. To use distributed training, set `num_workers` to the number of spark tasks you want to concurrently run during training xgboost model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99e71c1f-04f4-424d-99d2-25c8d56a4a06",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Make predictions and evaluate results\n",
    "\n",
    "The final step is to use the fitted model to make predictions on the test dataset and evaluate the model's performance. The model's performance on the test dataset provides an approximation of how it is likely to perform on new data.\n",
    "\n",
    "Computing evaluation metrics is important for understanding the quality of predictions, as well as for comparing models and tuning parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b867d2-0214-4cc4-ac4a-36b74673a60d",
   "metadata": {},
   "source": [
    "The `transform()` method of the pipeline model applies the full pipeline to the input dataset. The pipeline applies the feature processing steps to the dataset and then uses the fitted XGBoost Regressor model to make predictions. The pipeline returns a DataFrame with a new column `predictions`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b74c4d-a463-408d-8672-0dce534e2094",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = pipelineModel.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7710abfa-dd12-435d-973b-3858554d48ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.select(\"total_amount\", \"prediction\", *featuresCols).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03c63c20-40c4-420e-a0ff-c7722b48a0a2",
   "metadata": {},
   "source": [
    "A common way to evaluate the performance of a regression model is the calculate the [root mean squared error (RMSE)](https://spark.apache.org/docs/latest/mllib-evaluation-metrics.html#regression-model-evaluation). The value is not very informative on its own, but you can use it to compare different models. `CrossValidator` determines the best model by selecting the one that minimizes RMSE. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2336942-8379-426d-98d8-a521cce9813c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse = evaluator.evaluate(predictions)\n",
    "print(\"RMSE on our test set: %g\" % rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b173ff26-842c-45e1-9137-2597067341d9",
   "metadata": {},
   "source": [
    "You can also plot the results, as you did the original dataset. In this case, the hourly count of rentals shows a similar shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c10959c-0e27-4bbb-b91e-a28f2b36aaca",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.select(\"passenger_count\", \"prediction\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57286f1f-94d4-4b59-84e3-0fabbfdb9ede",
   "metadata": {},
   "source": [
    "## Save and reload the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7201b49-2980-481c-aae6-db648fd3e4a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%sh\n",
    "rm -rf /dbfs/tmp/xgboost/pipeline_001\n",
    "rm -rf /dbfs/tmp/xgboost/pipelineModel_001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932095f4-be51-44ac-abcb-b40b3f394814",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the pipeline that created the model\n",
    "pipeline.save('/tmp/xgboost/pipeline_001')\n",
    "\n",
    "# Save the model itself\n",
    "pipelineModel.save('/tmp/xgboost/pipelineModel_001')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ccea03-5c02-43da-94f9-e7041cde5454",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pipeline\n",
    "loaded_pipeline = Pipeline.load('/tmp/xgboost/pipeline_001')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa0bd1b-39de-4638-86fb-fdee21c84bc4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load and use the model\n",
    "from pyspark.ml import PipelineModel\n",
    "\n",
    "loaded_pipelineModel = PipelineModel.load('/tmp/xgboost/pipelineModel_001')\n",
    "\n",
    "# To represent new data, use the first 3 rows of the test dataset\n",
    "new_data = test.limit(3)\n",
    "\n",
    "# Make predictions with the loaded model\n",
    "new_preds = loaded_pipelineModel.transform(new_data)\n",
    "display(new_preds.select(\"total_amount\", \"prediction\", *featuresCols))"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Glue Python [PySpark and Ray] (SparkAnalytics 1.0)",
   "language": "python",
   "name": "conda-env-sm_glue_is-glue_pyspark__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-2:429704687514:image/sagemaker-sparkanalytics-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "Python_Glue_Session",
   "pygments_lexer": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
