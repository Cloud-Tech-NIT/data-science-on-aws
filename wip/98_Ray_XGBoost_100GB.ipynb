{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc882d63-47aa-4a8d-a617-426877630e37",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in /opt/conda/lib/python3.7/site-packages (1.6.2)\n",
      "Requirement already satisfied: xgboost_ray in /opt/conda/lib/python3.7/site-packages (0.1.15)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.7/site-packages (from xgboost) (1.4.1)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from xgboost) (1.21.6)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from xgboost_ray) (23.0)\n",
      "Requirement already satisfied: ray>=1.10 in /opt/conda/lib/python3.7/site-packages (from xgboost_ray) (2.3.0)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.7/site-packages (from xgboost_ray) (1.3.5)\n",
      "Requirement already satisfied: wrapt>=1.12.1 in /opt/conda/lib/python3.7/site-packages (from xgboost_ray) (1.15.0)\n",
      "Requirement already satisfied: attrs in /opt/conda/lib/python3.7/site-packages (from ray>=1.10->xgboost_ray) (22.2.0)\n",
      "Requirement already satisfied: protobuf!=3.19.5,>=3.15.3 in /opt/conda/lib/python3.7/site-packages (from ray>=1.10->xgboost_ray) (3.20.3)\n",
      "Requirement already satisfied: jsonschema in /opt/conda/lib/python3.7/site-packages (from ray>=1.10->xgboost_ray) (3.2.0)\n",
      "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from ray>=1.10->xgboost_ray) (1.0.5)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from ray>=1.10->xgboost_ray) (2.28.2)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from ray>=1.10->xgboost_ray) (3.9.0)\n",
      "Requirement already satisfied: frozenlist in /opt/conda/lib/python3.7/site-packages (from ray>=1.10->xgboost_ray) (1.3.3)\n",
      "Requirement already satisfied: virtualenv>=20.0.24 in /opt/conda/lib/python3.7/site-packages (from ray>=1.10->xgboost_ray) (20.20.0)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from ray>=1.10->xgboost_ray) (4.4.0)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.7/site-packages (from ray>=1.10->xgboost_ray) (6.0)\n",
      "Requirement already satisfied: click>=7.0 in /opt/conda/lib/python3.7/site-packages (from ray>=1.10->xgboost_ray) (7.1.2)\n",
      "Requirement already satisfied: aiosignal in /opt/conda/lib/python3.7/site-packages (from ray>=1.10->xgboost_ray) (1.3.1)\n",
      "Requirement already satisfied: grpcio>=1.32.0 in /opt/conda/lib/python3.7/site-packages (from ray>=1.10->xgboost_ray) (1.51.3)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas->xgboost_ray) (2019.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.7/site-packages (from pandas->xgboost_ray) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas->xgboost_ray) (1.14.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.8.3 in /opt/conda/lib/python3.7/site-packages (from virtualenv>=20.0.24->ray>=1.10->xgboost_ray) (4.13.0)\n",
      "Requirement already satisfied: distlib<1,>=0.3.6 in /opt/conda/lib/python3.7/site-packages (from virtualenv>=20.0.24->ray>=1.10->xgboost_ray) (0.3.6)\n",
      "Requirement already satisfied: platformdirs<4,>=2.4 in /opt/conda/lib/python3.7/site-packages (from virtualenv>=20.0.24->ray>=1.10->xgboost_ray) (3.0.0)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from jsonschema->ray>=1.10->xgboost_ray) (59.3.0)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in /opt/conda/lib/python3.7/site-packages (from jsonschema->ray>=1.10->xgboost_ray) (0.15.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->ray>=1.10->xgboost_ray) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->ray>=1.10->xgboost_ray) (2.8)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.7/site-packages (from requests->ray>=1.10->xgboost_ray) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->ray>=1.10->xgboost_ray) (1.26.14)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata>=4.8.3->virtualenv>=20.0.24->ray>=1.10->xgboost_ray) (3.13.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install xgboost xgboost_ray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de856b0a-8b1a-4a53-8e04-30bf90ca3009",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "import ray\n",
    "ray.shutdown()\n",
    "\n",
    "from ray import tune\n",
    "from ray.air.checkpoint import Checkpoint\n",
    "from ray.train.constants import TRAIN_DATASET_KEY\n",
    "\n",
    "from ray.train.xgboost import XGBoostCheckpoint, XGBoostTrainer\n",
    "from ray.air.config import ScalingConfig\n",
    "from ray.data.preprocessor import Preprocessor\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "064be4a4-7e70-488c-a41c-70cd52955bc6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def ray_start_4_cpus():\n",
    "    address_info = ray.init(num_cpus=4) #,log_dir='/tmp/ray_results/')\n",
    "    yield address_info\n",
    "    # The code after the yield will run as teardown code.\n",
    "    ray.shutdown()\n",
    "\n",
    "def ray_start_8_cpus():\n",
    "    address_info = ray.init(num_cpus=8) #,log_dir='/tmp/ray_results/')\n",
    "    yield address_info\n",
    "    # The code after the yield will run as teardown code.\n",
    "    ray.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8dccd4fc-f974-4a02-aada-a162ed64f9e1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object ray_start_8_cpus at 0x7ff3c88679d0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ray_start_8_cpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7a776f53-5d80-43e6-a149-b6a163055873",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_raw = load_breast_cancer()\n",
    "\n",
    "dataset_df = pd.DataFrame(data_raw[\"data\"], columns=data_raw[\"feature_names\"])\n",
    "dataset_df[\"target\"] = data_raw[\"target\"]\n",
    "\n",
    "train_df, test_df = train_test_split(dataset_df, test_size=0.3)\n",
    "\n",
    "train_dataset = ray.data.from_pandas(train_df)\n",
    "valid_dataset = ray.data.from_pandas(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d23b63b2-cdb8-4c96-992b-7c347bf2fe80",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-bead06785e95>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;31m# ignore=[\"total_amount\"],  # Optional list of columns to ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     filetype=RayFileType.PARQUET)\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/xgboost_ray/matrix.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, label, weight, feature_weights, base_margin, missing, label_lower_bound, label_upper_bound, feature_names, feature_types, qid, enable_categorical, num_actors, filetype, ignore, distributed, sharding, lazy, **kwargs)\u001b[0m\n\u001b[1;32m    735\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdistributed\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 737\u001b[0;31m             \u001b[0mdistributed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_detect_distributed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    739\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdistributed\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_can_load_distributed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/xgboost_ray/matrix.py\u001b[0m in \u001b[0;36m_detect_distributed\u001b[0;34m(source)\u001b[0m\n\u001b[1;32m    954\u001b[0m     \u001b[0;34m\"\"\"Returns True if we should try to use distributed data loading\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    955\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mxgboost_ray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_sources\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodin\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mModin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 956\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_can_load_distributed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    957\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    958\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mModin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_data_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/xgboost_ray/matrix.py\u001b[0m in \u001b[0;36m_can_load_distributed\u001b[0;34m(source)\u001b[0m\n\u001b[1;32m    940\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    941\u001b[0m         \u001b[0;31m# Sequence of strings should point to files or URLs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 942\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    943\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m         \u001b[0;31m# If we get an iterable but not a sequence, the best we can do\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "from xgboost_ray import RayDMatrix, RayFileType\n",
    "\n",
    "# We can also pass a list of files\n",
    "path = list(sorted(glob.glob(\"./data/nyc-taxi/*.snappy.parquet\")))\n",
    "\n",
    "# This argument will be passed to `pd.read_parquet()`\n",
    "columns = [\n",
    "    \"passenger_count\",\n",
    "    \"trip_distance\", \"pickup_longitude\", \"pickup_latitude\",\n",
    "    \"dropoff_longitude\", \"dropoff_latitude\",\n",
    "    \"fare_amount\", \"extra\", \"mta_tax\", \"tip_amount\",\n",
    "    \"tolls_amount\", \"total_amount\"\n",
    "]\n",
    "\n",
    "dtrain = RayDMatrix(\n",
    "    path,\n",
    "    label=\"total_amount\",  # Will select this column as the label\n",
    "    columns=columns,\n",
    "    # ignore=[\"total_amount\"],  # Optional list of columns to ignore\n",
    "    filetype=RayFileType.PARQUET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "55cfb467-18dd-4912-9c24-7492dd8445a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def get_num_trees(booster: xgb.Booster) -> int:\n",
    "#     data = [json.loads(d) for d in booster.get_dump(dump_format=\"json\")]\n",
    "#     return len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7c4f78dd-e428-4e52-8afd-3eb5d39045a9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-10 03:41:40,853\tWARNING callback.py:109 -- The TensorboardX logger cannot be instantiated because either TensorboardX or one of it's dependencies is not installed. Please make sure you have the latest version of TensorboardX installed: `pip install -U tensorboardx`\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2023-03-10 03:41:51</td></tr>\n",
       "<tr><td>Running for: </td><td>00:00:10.45        </td></tr>\n",
       "<tr><td>Memory:      </td><td>17.0/31.0 GiB      </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using FIFO scheduling algorithm.<br>Resources requested: 0/8 CPUs, 0/0 GPUs, 0.0/8.04 GiB heap, 0.0/4.02 GiB objects\n",
       "    </div>\n",
       "    \n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name                </th><th>status    </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  train-logloss</th><th style=\"text-align: right;\">  train-error</th><th style=\"text-align: right;\">  valid-logloss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>XGBoostTrainer_7809e_00000</td><td>TERMINATED</td><td>169.255.255.2:11495</td><td style=\"text-align: right;\">    11</td><td style=\"text-align: right;\">         8.27039</td><td style=\"text-align: right;\">       0.054291</td><td style=\"text-align: right;\">   0.00505051</td><td style=\"text-align: right;\">       0.121991</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(XGBoostTrainer pid=11495)\u001b[0m 2023-03-10 03:41:43,018\tINFO bulk_executor.py:39 -- Executing DAG InputDataBuffer[Input] -> AllToAllOperator[repartition]\n",
      "\u001b[2m\u001b[36m(XGBoostTrainer pid=11495)\u001b[0m 2023-03-10 03:41:44,516\tINFO bulk_executor.py:39 -- Executing DAG InputDataBuffer[Input] -> AllToAllOperator[repartition]\n",
      "\u001b[2m\u001b[36m(XGBoostTrainer pid=11495)\u001b[0m 2023-03-10 03:41:44,607\tWARNING plan.py:524 -- Warning: The Ray cluster currently does not have any available CPUs. The Dataset job will hang unless more CPUs are freed up. A common reason is that cluster resources are used by Actors or Tune trials; see the following link for more details: https://docs.ray.io/en/master/data/dataset-internals.html#datasets-and-tune\n",
      "\u001b[2m\u001b[36m(XGBoostTrainer pid=11495)\u001b[0m 2023-03-10 03:41:47,698\tINFO tracker.py:217 -- start listen on 169.255.255.2:47043\n",
      "\u001b[2m\u001b[36m(_RemoteRayXGBoostActor pid=11559)\u001b[0m [03:41:47] task [xgboost.ray]:139674558309392 got new rank 0\n",
      "\u001b[2m\u001b[36m(_RemoteRayXGBoostActor pid=11560)\u001b[0m [03:41:47] task [xgboost.ray]:140514935999824 got new rank 1\n",
      "\u001b[2m\u001b[36m(_RemoteRayXGBoostActor pid=11562)\u001b[0m [03:41:48] task [xgboost.ray]:139896126590032 got new rank 3\n",
      "\u001b[2m\u001b[36m(_RemoteRayXGBoostActor pid=11561)\u001b[0m [03:41:48] task [xgboost.ray]:139986088061904 got new rank 2\n",
      "\u001b[2m\u001b[36m(XGBoostTrainer pid=11495)\u001b[0m 2023-03-10 03:41:48,165\tINFO tracker.py:381 -- @tracker All of 4 nodes getting started\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"trialProgress\">\n",
       "  <h3>Trial Progress</h3>\n",
       "  <table>\n",
       "<thead>\n",
       "<tr><th>Trial name                </th><th>date               </th><th>done  </th><th>episodes_total  </th><th>experiment_id                   </th><th style=\"text-align: right;\">  experiment_tag</th><th>hostname                                                  </th><th style=\"text-align: right;\">  iterations_since_restore</th><th>node_ip      </th><th style=\"text-align: right;\">  pid</th><th>should_checkpoint  </th><th style=\"text-align: right;\">  time_since_restore</th><th style=\"text-align: right;\">  time_this_iter_s</th><th style=\"text-align: right;\">  time_total_s</th><th style=\"text-align: right;\">  timestamp</th><th style=\"text-align: right;\">  timesteps_since_restore</th><th>timesteps_total  </th><th style=\"text-align: right;\">  train-error</th><th style=\"text-align: right;\">  train-logloss</th><th style=\"text-align: right;\">  training_iteration</th><th>trial_id   </th><th style=\"text-align: right;\">  valid-error</th><th style=\"text-align: right;\">  valid-logloss</th><th style=\"text-align: right;\">  warmup_time</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>XGBoostTrainer_7809e_00000</td><td>2023-03-10_03-41-51</td><td>True  </td><td>                </td><td>a205b4d618b14a7aa7ec5a0ffd9dafdd</td><td style=\"text-align: right;\">               0</td><td>datascience-1-0-ml-m5-2xlarge-edc54522b6c2075d0551eb4e13d2</td><td style=\"text-align: right;\">                        11</td><td>169.255.255.2</td><td style=\"text-align: right;\">11495</td><td>True               </td><td style=\"text-align: right;\">             8.27039</td><td style=\"text-align: right;\">         0.0733163</td><td style=\"text-align: right;\">       8.27039</td><td style=\"text-align: right;\"> 1678419711</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">   0.00505051</td><td style=\"text-align: right;\">       0.054291</td><td style=\"text-align: right;\">                  11</td><td>7809e_00000</td><td style=\"text-align: right;\">     0.047619</td><td style=\"text-align: right;\">       0.121991</td><td style=\"text-align: right;\">   0.00598192</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>\n",
       "<style>\n",
       ".trialProgress {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".trialProgress h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".trialProgress td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(XGBoostTrainer pid=11495)\u001b[0m 2023-03-10 03:41:51,007\tINFO tracker.py:387 -- @tracker All nodes finishes job\n",
      "2023-03-10 03:41:51,315\tINFO tune.py:799 -- Total run time: 10.46 seconds (10.42 seconds for the tuning loop).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result(metrics={'train-logloss': 0.05429103939953928, 'train-error': 0.00505050505050505, 'valid-logloss': 0.1219907808339312, 'valid-error': 0.04761904761904762, 'should_checkpoint': True, 'done': True, 'trial_id': '7809e_00000', 'experiment_tag': '0'}, error=None, log_dir=PosixPath('/root/ray_results/XGBoostTrainer_2023-03-10_03-41-40/XGBoostTrainer_7809e_00000_0_2023-03-10_03-41-40'))\n"
     ]
    }
   ],
   "source": [
    "# params = {\n",
    "#     \"tree_method\": \"approx\",\n",
    "#     \"objective\": \"binary:logistic\",\n",
    "#     \"eval_metric\": [\"logloss\", \"error\"],\n",
    "# }\n",
    "\n",
    "hyperparameters = {\n",
    "    \"eta\": \"0.2\",\n",
    "    \"gamma\": \"4\",\n",
    "    \"max_depth\": \"5\",\n",
    "    \"min_child_weight\": \"6\",\n",
    "    \"num_round\": \"50\",\n",
    "    \"objective\": \"reg:squarederror\",\n",
    "    \"subsample\": \"0.7\",\n",
    "    \"verbosity\": \"2\",\n",
    "    \"content_type\":\"parquet\",\n",
    "}\n",
    "\n",
    "scale_config = ScalingConfig(num_workers=4)\n",
    "\n",
    "trainer = XGBoostTrainer(\n",
    "    scaling_config=scale_config,\n",
    "    label_column=\"target\",\n",
    "    params=params,\n",
    "    datasets={TRAIN_DATASET_KEY: train_dataset, \"valid\": valid_dataset},\n",
    ")\n",
    "result = trainer.fit()\n",
    "\n",
    "print(result)\n",
    "\n",
    "# trainer = XGBoostTrainer(\n",
    "#     scaling_config=ScalingConfig(\n",
    "# #        trainer_resources={\"CPU\": 0},\n",
    "#         num_workers=8,\n",
    "# #        placement_strategy=\"SPREAD\",\n",
    "#         _max_cpu_fraction_per_node=0.9,\n",
    "#     ),\n",
    "#     label_column=\"target\",\n",
    "#     params=params,\n",
    "#     datasets={TRAIN_DATASET_KEY: train_dataset, \"valid\": valid_dataset},\n",
    "# )\n",
    "\n",
    "# result = trainer.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b961de00-5ec1-4465-886f-a7113b97fe81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "95c290a3-e443-4214-8ba2-2cfca79818c4",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Resume from checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "254d27fc-8184-4dd4-a6f8-9484a64002ad",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-10 03:38:19,263\tWARNING callback.py:109 -- The TensorboardX logger cannot be instantiated because either TensorboardX or one of it's dependencies is not installed. Please make sure you have the latest version of TensorboardX installed: `pip install -U tensorboardx`\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2023-03-10 03:38:29</td></tr>\n",
       "<tr><td>Running for: </td><td>00:00:10.63        </td></tr>\n",
       "<tr><td>Memory:      </td><td>16.9/31.0 GiB      </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using FIFO scheduling algorithm.<br>Resources requested: 0/8 CPUs, 0/0 GPUs, 0.0/8.04 GiB heap, 0.0/4.02 GiB objects\n",
       "    </div>\n",
       "    \n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name                </th><th>status    </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  train-logloss</th><th style=\"text-align: right;\">  train-error</th><th style=\"text-align: right;\">  valid-logloss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>XGBoostTrainer_ffe1b_00000</td><td>TERMINATED</td><td>169.255.255.2:7544</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         7.91851</td><td style=\"text-align: right;\">       0.149229</td><td style=\"text-align: right;\">   0.00505051</td><td style=\"text-align: right;\">       0.217007</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(XGBoostTrainer pid=7544)\u001b[0m 2023-03-10 03:38:21,945\tINFO bulk_executor.py:39 -- Executing DAG InputDataBuffer[Input] -> AllToAllOperator[repartition]\n",
      "\u001b[2m\u001b[36m(XGBoostTrainer pid=7544)\u001b[0m 2023-03-10 03:38:23,441\tINFO bulk_executor.py:39 -- Executing DAG InputDataBuffer[Input] -> AllToAllOperator[repartition]\n",
      "\u001b[2m\u001b[36m(XGBoostTrainer pid=7544)\u001b[0m 2023-03-10 03:38:26,698\tINFO tracker.py:217 -- start listen on 169.255.255.2:49487\n",
      "\u001b[2m\u001b[36m(_RemoteRayXGBoostActor pid=7610)\u001b[0m [03:38:26] task [xgboost.ray]:139796614291600 got new rank 0\n",
      "\u001b[2m\u001b[36m(_RemoteRayXGBoostActor pid=7611)\u001b[0m [03:38:26] task [xgboost.ray]:140051997375568 got new rank 1\n",
      "\u001b[2m\u001b[36m(_RemoteRayXGBoostActor pid=7612)\u001b[0m [03:38:27] task [xgboost.ray]:139786840095120 got new rank 2\n",
      "\u001b[2m\u001b[36m(XGBoostTrainer pid=7544)\u001b[0m 2023-03-10 03:38:27,161\tINFO tracker.py:381 -- @tracker All of 4 nodes getting started\n",
      "\u001b[2m\u001b[36m(_RemoteRayXGBoostActor pid=7613)\u001b[0m [03:38:27] task [xgboost.ray]:140119573118160 got new rank 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"trialProgress\">\n",
       "  <h3>Trial Progress</h3>\n",
       "  <table>\n",
       "<thead>\n",
       "<tr><th>Trial name                </th><th>date               </th><th>done  </th><th>episodes_total  </th><th>experiment_id                   </th><th style=\"text-align: right;\">  experiment_tag</th><th>hostname                                                  </th><th style=\"text-align: right;\">  iterations_since_restore</th><th>node_ip      </th><th style=\"text-align: right;\">  pid</th><th>should_checkpoint  </th><th style=\"text-align: right;\">  time_since_restore</th><th style=\"text-align: right;\">  time_this_iter_s</th><th style=\"text-align: right;\">  time_total_s</th><th style=\"text-align: right;\">  timestamp</th><th style=\"text-align: right;\">  timesteps_since_restore</th><th>timesteps_total  </th><th style=\"text-align: right;\">  train-error</th><th style=\"text-align: right;\">  train-logloss</th><th style=\"text-align: right;\">  training_iteration</th><th>trial_id   </th><th style=\"text-align: right;\">  valid-error</th><th style=\"text-align: right;\">  valid-logloss</th><th style=\"text-align: right;\">  warmup_time</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>XGBoostTrainer_ffe1b_00000</td><td>2023-03-10_03-38-29</td><td>True  </td><td>                </td><td>a9bde25d93194f1ba5826af5254e9902</td><td style=\"text-align: right;\">               0</td><td>datascience-1-0-ml-m5-2xlarge-edc54522b6c2075d0551eb4e13d2</td><td style=\"text-align: right;\">                         6</td><td>169.255.255.2</td><td style=\"text-align: right;\"> 7544</td><td>True               </td><td style=\"text-align: right;\">             7.91851</td><td style=\"text-align: right;\">          0.311455</td><td style=\"text-align: right;\">       7.91851</td><td style=\"text-align: right;\"> 1678419509</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">   0.00505051</td><td style=\"text-align: right;\">       0.149229</td><td style=\"text-align: right;\">                   6</td><td>ffe1b_00000</td><td style=\"text-align: right;\">    0.0654762</td><td style=\"text-align: right;\">       0.217007</td><td style=\"text-align: right;\">   0.00587487</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>\n",
       "<style>\n",
       ".trialProgress {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".trialProgress h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".trialProgress td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(XGBoostTrainer pid=7544)\u001b[0m 2023-03-10 03:38:29,393\tINFO tracker.py:387 -- @tracker All nodes finishes job\n",
      "2023-03-10 03:38:29,903\tINFO tune.py:799 -- Total run time: 10.64 seconds (10.60 seconds for the tuning loop).\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'get_num_trees' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-2a24d3eda6b5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mcheckpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mXGBoostCheckpoint\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mxgb_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheckpoint\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0mget_num_trees\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxgb_model\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'get_num_trees' is not defined"
     ]
    }
   ],
   "source": [
    "# trainer = XGBoostTrainer(\n",
    "#     scaling_config=scale_config,\n",
    "#     label_column=\"target\",\n",
    "#     params=params,\n",
    "#     num_boost_round=5,\n",
    "#     datasets={TRAIN_DATASET_KEY: train_dataset, \"valid\": valid_dataset},\n",
    "# )\n",
    "# result = trainer.fit()\n",
    "# checkpoint = XGBoostCheckpoint.from_checkpoint(result.checkpoint)\n",
    "# xgb_model = checkpoint.get_model()\n",
    "# assert get_num_trees(xgb_model) == 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee0b5d1d-9897-44f0-93f9-30c69b6303a8",
   "metadata": {},
   "source": [
    "# Tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "35e3d3da-cbca-4f82-b499-33836e145e36",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-10 03:39:24,364\tWARNING callback.py:109 -- The TensorboardX logger cannot be instantiated because either TensorboardX or one of it's dependencies is not installed. Please make sure you have the latest version of TensorboardX installed: `pip install -U tensorboardx`\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2023-03-10 03:40:22</td></tr>\n",
       "<tr><td>Running for: </td><td>00:00:57.82        </td></tr>\n",
       "<tr><td>Memory:      </td><td>18.4/31.0 GiB      </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using FIFO scheduling algorithm.<br>Resources requested: 8.0/8 CPUs, 0/0 GPUs, 0.0/8.04 GiB heap, 0.0/4.02 GiB objects\n",
       "    </div>\n",
       "    \n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name                </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  params/max_depth</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>XGBoostTrainer_26aea_00000</td><td>RUNNING </td><td>169.255.255.2:8617</td><td style=\"text-align: right;\">                 3</td></tr>\n",
       "<tr><td>XGBoostTrainer_26aea_00001</td><td>RUNNING </td><td>169.255.255.2:8683</td><td style=\"text-align: right;\">                 2</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(XGBoostTrainer pid=8617)\u001b[0m 2023-03-10 03:39:26,961\tWARNING plan.py:524 -- Warning: The Ray cluster currently does not have any available CPUs. The Dataset job will hang unless more CPUs are freed up. A common reason is that cluster resources are used by Actors or Tune trials; see the following link for more details: https://docs.ray.io/en/master/data/dataset-internals.html#datasets-and-tune\n",
      "\u001b[2m\u001b[36m(XGBoostTrainer pid=8617)\u001b[0m 2023-03-10 03:39:26,962\tWARNING plan.py:524 -- Warning: The Ray cluster currently does not have any available CPUs. The Dataset job will hang unless more CPUs are freed up. A common reason is that cluster resources are used by Actors or Tune trials; see the following link for more details: https://docs.ray.io/en/master/data/dataset-internals.html#datasets-and-tune\n",
      "\u001b[2m\u001b[36m(XGBoostTrainer pid=8617)\u001b[0m 2023-03-10 03:39:26,996\tWARNING plan.py:524 -- Warning: The Ray cluster currently does not have any available CPUs. The Dataset job will hang unless more CPUs are freed up. A common reason is that cluster resources are used by Actors or Tune trials; see the following link for more details: https://docs.ray.io/en/master/data/dataset-internals.html#datasets-and-tune\n",
      "\u001b[2m\u001b[36m(XGBoostTrainer pid=8617)\u001b[0m 2023-03-10 03:39:26,997\tINFO bulk_executor.py:39 -- Executing DAG InputDataBuffer[Input] -> AllToAllOperator[repartition]\n",
      "\u001b[2m\u001b[36m(XGBoostTrainer pid=8617)\u001b[0m 2023-03-10 03:39:26,999\tWARNING plan.py:524 -- Warning: The Ray cluster currently does not have any available CPUs. The Dataset job will hang unless more CPUs are freed up. A common reason is that cluster resources are used by Actors or Tune trials; see the following link for more details: https://docs.ray.io/en/master/data/dataset-internals.html#datasets-and-tune\n",
      "\u001b[2m\u001b[36m(XGBoostTrainer pid=8617)\u001b[0m 2023-03-10 03:39:27,000\tWARNING plan.py:524 -- Warning: The Ray cluster currently does not have any available CPUs. The Dataset job will hang unless more CPUs are freed up. A common reason is that cluster resources are used by Actors or Tune trials; see the following link for more details: https://docs.ray.io/en/master/data/dataset-internals.html#datasets-and-tune\n",
      "\u001b[2m\u001b[36m(XGBoostTrainer pid=8683)\u001b[0m 2023-03-10 03:39:30,063\tWARNING plan.py:524 -- Warning: The Ray cluster currently does not have any available CPUs. The Dataset job will hang unless more CPUs are freed up. A common reason is that cluster resources are used by Actors or Tune trials; see the following link for more details: https://docs.ray.io/en/master/data/dataset-internals.html#datasets-and-tune\n",
      "\u001b[2m\u001b[36m(XGBoostTrainer pid=8683)\u001b[0m 2023-03-10 03:39:30,065\tWARNING plan.py:524 -- Warning: The Ray cluster currently does not have any available CPUs. The Dataset job will hang unless more CPUs are freed up. A common reason is that cluster resources are used by Actors or Tune trials; see the following link for more details: https://docs.ray.io/en/master/data/dataset-internals.html#datasets-and-tune\n",
      "\u001b[2m\u001b[36m(XGBoostTrainer pid=8683)\u001b[0m 2023-03-10 03:39:30,094\tWARNING plan.py:524 -- Warning: The Ray cluster currently does not have any available CPUs. The Dataset job will hang unless more CPUs are freed up. A common reason is that cluster resources are used by Actors or Tune trials; see the following link for more details: https://docs.ray.io/en/master/data/dataset-internals.html#datasets-and-tune\n",
      "\u001b[2m\u001b[36m(XGBoostTrainer pid=8683)\u001b[0m 2023-03-10 03:39:30,096\tINFO bulk_executor.py:39 -- Executing DAG InputDataBuffer[Input] -> AllToAllOperator[repartition]\n",
      "\u001b[2m\u001b[36m(XGBoostTrainer pid=8683)\u001b[0m 2023-03-10 03:39:30,100\tWARNING plan.py:524 -- Warning: The Ray cluster currently does not have any available CPUs. The Dataset job will hang unless more CPUs are freed up. A common reason is that cluster resources are used by Actors or Tune trials; see the following link for more details: https://docs.ray.io/en/master/data/dataset-internals.html#datasets-and-tune\n",
      "\u001b[2m\u001b[36m(XGBoostTrainer pid=8683)\u001b[0m 2023-03-10 03:39:30,101\tWARNING plan.py:524 -- Warning: The Ray cluster currently does not have any available CPUs. The Dataset job will hang unless more CPUs are freed up. A common reason is that cluster resources are used by Actors or Tune trials; see the following link for more details: https://docs.ray.io/en/master/data/dataset-internals.html#datasets-and-tune\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[1m\u001b[36m(autoscaler +1m37s)\u001b[0m Tip: use `ray status` to view detailed cluster status. To disable these messages, set RAY_SCHEDULER_EVENTS=0.\n",
      "\u001b[2m\u001b[1m\u001b[33m(autoscaler +1m37s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(autoscaler +2m12s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-10 03:40:19,166\tWARNING tune.py:147 -- Stop signal received (e.g. via SIGINT/Ctrl+C), ending Ray Tune run. This will try to checkpoint the experiment state one last time. Press CTRL+C (or send SIGINT/SIGKILL/SIGTERM) to skip. \n",
      "2023-03-10 03:40:22,198\tERROR tune.py:794 -- Trials did not complete: [XGBoostTrainer_26aea_00000, XGBoostTrainer_26aea_00001]\n",
      "2023-03-10 03:40:22,199\tINFO tune.py:799 -- Total run time: 57.84 seconds (57.79 seconds for the tuning loop).\n",
      "2023-03-10 03:40:22,200\tWARNING tune.py:805 -- Experiment has been interrupted, but the most recent state was saved. You can continue running this experiment by passing `resume=True` to `tune.run()`\n"
     ]
    }
   ],
   "source": [
    "trainer = XGBoostTrainer(\n",
    "    scaling_config=scale_config,\n",
    "    label_column=\"target\",\n",
    "    params={**params, **{\"max_depth\": 1}},\n",
    "    datasets={TRAIN_DATASET_KEY: train_dataset, \"valid\": valid_dataset},\n",
    ")\n",
    "\n",
    "tune.run(\n",
    "    trainer.as_trainable(),\n",
    "    config={\"params\": {\"max_depth\": tune.randint(2, 4)}},\n",
    "    num_samples=2,\n",
    ")\n",
    "\n",
    "# # Make sure original Trainer is not affected.\n",
    "# assert trainer.params[\"max_depth\"] == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d6ec367-3250-4aad-ab81-44054268af14",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Move checkpoint to a different directory.\n",
    "# checkpoint_dict = result.checkpoint.to_dict()\n",
    "# checkpoint = Checkpoint.from_dict(checkpoint_dict)\n",
    "# checkpoint_path = checkpoint.to_directory(tmpdir)\n",
    "# resume_from = Checkpoint.from_directory(checkpoint_path)\n",
    "\n",
    "# trainer = XGBoostTrainer(\n",
    "#     scaling_config=scale_config,\n",
    "#     label_column=\"target\",\n",
    "#     params=params,\n",
    "#     num_boost_round=5,\n",
    "#     datasets={TRAIN_DATASET_KEY: train_dataset, \"valid\": valid_dataset},\n",
    "#     resume_from_checkpoint=resume_from,\n",
    "# )\n",
    "# result = trainer.fit()\n",
    "# checkpoint = XGBoostCheckpoint.from_checkpoint(result.checkpoint)\n",
    "# model = checkpoint.get_model()\n",
    "# assert get_num_trees(model) == 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127534f9-efe8-4b63-8f4d-76e0bec8265a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# @pytest.mark.parametrize(\n",
    "#     \"freq_end_expected\",\n",
    "#     [\n",
    "#         (4, True, 7),  # 4, 8, 12, 16, 20, 24, 25\n",
    "#         (4, False, 6),  # 4, 8, 12, 16, 20, 24\n",
    "#         (5, True, 5),  # 5, 10, 15, 20, 25\n",
    "#         (0, True, 1),\n",
    "#         (0, False, 0),\n",
    "#     ],\n",
    "# )\n",
    "# def test_checkpoint_freq(ray_start_4_cpus, freq_end_expected):\n",
    "#     freq, end, expected = freq_end_expected\n",
    "\n",
    "#     train_dataset = ray.data.from_pandas(train_df)\n",
    "#     valid_dataset = ray.data.from_pandas(test_df)\n",
    "#     trainer = XGBoostTrainer(\n",
    "#         run_config=ray.air.RunConfig(\n",
    "#             checkpoint_config=ray.air.CheckpointConfig(\n",
    "#                 checkpoint_frequency=freq, checkpoint_at_end=end\n",
    "#             )\n",
    "#         ),\n",
    "#         scaling_config=scale_config,\n",
    "#         label_column=\"target\",\n",
    "#         params=params,\n",
    "#         num_boost_round=25,\n",
    "#         datasets={TRAIN_DATASET_KEY: train_dataset, \"valid\": valid_dataset},\n",
    "#     )\n",
    "#     result = trainer.fit()\n",
    "\n",
    "#     # Assert number of checkpoints\n",
    "#     assert len(result.best_checkpoints) == expected, str(\n",
    "#         [\n",
    "#             (metrics[\"training_iteration\"], _cp._local_path)\n",
    "#             for _cp, metrics in result.best_checkpoints\n",
    "#         ]\n",
    "#     )\n",
    "\n",
    "#     # Assert checkpoint numbers are increasing\n",
    "#     cp_paths = [cp._local_path for cp, _ in result.best_checkpoints]\n",
    "#     assert cp_paths == sorted(cp_paths), str(cp_paths)\n",
    "\n",
    "\n",
    "# def test_preprocessor_in_checkpoint(ray_start_4_cpus, tmpdir):\n",
    "#     train_dataset = ray.data.from_pandas(train_df)\n",
    "#     valid_dataset = ray.data.from_pandas(test_df)\n",
    "\n",
    "#     class DummyPreprocessor(Preprocessor):\n",
    "#         def __init__(self):\n",
    "#             super().__init__()\n",
    "#             self.is_same = True\n",
    "\n",
    "#         def fit(self, dataset):\n",
    "#             self.fitted_ = True\n",
    "\n",
    "#         def _transform_pandas(self, df: \"pd.DataFrame\") -> \"pd.DataFrame\":\n",
    "#             return df\n",
    "\n",
    "#     trainer = XGBoostTrainer(\n",
    "#         scaling_config=scale_config,\n",
    "#         label_column=\"target\",\n",
    "#         params=params,\n",
    "#         datasets={TRAIN_DATASET_KEY: train_dataset, \"valid\": valid_dataset},\n",
    "#         preprocessor=DummyPreprocessor(),\n",
    "#     )\n",
    "#     result = trainer.fit()\n",
    "\n",
    "#     # Move checkpoint to a different directory.\n",
    "#     checkpoint_dict = result.checkpoint.to_dict()\n",
    "#     checkpoint = Checkpoint.from_dict(checkpoint_dict)\n",
    "#     checkpoint_path = checkpoint.to_directory(tmpdir)\n",
    "#     resume_from = Checkpoint.from_directory(checkpoint_path)\n",
    "\n",
    "#     resume_from = XGBoostCheckpoint.from_checkpoint(resume_from)\n",
    "\n",
    "#     model, preprocessor = resume_from.get_model(), resume_from.get_preprocessor()\n",
    "#     assert get_num_trees(model) == 10\n",
    "#     assert preprocessor.is_same\n",
    "#     assert preprocessor.fitted_\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf7fb67-0503-47d9-91c2-eb36f2b1b535",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# train_dataset = ray.data.from_pandas(train_df)\n",
    "# valid_dataset = ray.data.from_pandas(test_df)\n",
    "# #with pytest.raises(KeyError, match=TRAIN_DATASET_KEY):\n",
    "# XGBoostTrainer(\n",
    "#     scaling_config=ScalingConfig(num_workers=2),\n",
    "#     label_column=\"target\",\n",
    "#     params=params,\n",
    "#     datasets={\"valid\": valid_dataset},\n",
    "# )\n",
    "# with pytest.raises(KeyError, match=\"dmatrix_params\"):\n",
    "#     XGBoostTrainer(\n",
    "#         scaling_config=ScalingConfig(num_workers=2),\n",
    "#         label_column=\"target\",\n",
    "#         params=params,\n",
    "#         dmatrix_params={\"data\": {}},\n",
    "#         datasets={TRAIN_DATASET_KEY: train_dataset, \"valid\": valid_dataset},\n",
    "#     )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a37ecc-df14-4985-9eac-fd1849b5005b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def test_distributed_data_loading(ray_start_4_cpus):\n",
    "#     \"\"\"Checks that XGBoostTrainer does distributed data loading for Ray Datasets.\"\"\"\n",
    "\n",
    "#     class DummyXGBoostTrainer(XGBoostTrainer):\n",
    "#         def _train(self, params, dtrain, **kwargs):\n",
    "#             assert dtrain.distributed\n",
    "#             return super()._train(params=params, dtrain=dtrain, **kwargs)\n",
    "\n",
    "#     train_dataset = ray.data.from_pandas(train_df)\n",
    "\n",
    "#     trainer = DummyXGBoostTrainer(\n",
    "#         scaling_config=ScalingConfig(num_workers=2),\n",
    "#         label_column=\"target\",\n",
    "#         params=params,\n",
    "#         datasets={TRAIN_DATASET_KEY: train_dataset},\n",
    "#     )\n",
    "\n",
    "#     assert trainer.dmatrix_params[TRAIN_DATASET_KEY][\"distributed\"]\n",
    "#     trainer.fit()\n"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   }
  ],
  "instance_type": "ml.m5.2xlarge",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
